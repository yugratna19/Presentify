{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html lang=\"en\">\\n  <head>\\n    <meta charset=\"utf-8\"/>\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/>\\n<!-- new favicon config and versions by realfavicongenerator.net -->\\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png\">\\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png\">\\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png\">\\n<link rel=\"manifest\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest\">\\n<link rel=\"mask-icon\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg\" color=\"#b31b1b\">\\n<link rel=\"shortcut icon\" href=\"https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico\">\\n<meta name=\"msapplication-TileColor\" content=\"#b31b1b\">\\n<meta name=\"msapplication-config\" content=\"images/icons/browserconfig.xml\">\\n<meta name=\"theme-color\" content=\"#b31b1b\">\\n<!-- end favicon config -->\\n<title>Advanced Search | arXiv e-print repository</title>\\n<script defer src=\"https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js\"></script>\\n<link rel=\"stylesheet\" href=\"https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css\" />\\n<script type=\"text/x-mathjax-config\">\\n  MathJax.Hub.Config({\\n    messageStyle: \"none\",\\n    extensions: [\"tex2jax.js\"],\\n    jax: [\"input/TeX\", \"output/HTML-CSS\"],\\n    tex2jax: {\\n      inlineMath: [ [\\'$\\',\\'$\\'], [\"\\\\\\\\(\",\"\\\\\\\\)\"] ],\\n      displayMath: [ [\\'$$\\',\\'$$\\'], [\"\\\\\\\\[\",\"\\\\\\\\]\"] ],\\n      processEscapes: true,\\n      ignoreClass: \\'.*\\',\\n      processClass: \\'mathjax.*\\'\\n    },\\n    TeX: {\\n        extensions: [\"AMSmath.js\", \"AMSsymbols.js\", \"noErrors.js\"],\\n        noErrors: {\\n          inlineDelimiters: [\"$\",\"$\"],\\n          multiLine: false,\\n          style: {\\n            \"font-size\": \"normal\",\\n            \"border\": \"\"\\n          }\\n        }\\n    },\\n    \"HTML-CSS\": { availableFonts: [\"TeX\"] }\\n  });\\n</script>\\n<script src=\\'//static.arxiv.org/MathJax-2.7.3/MathJax.js\\'></script>\\n<script src=\"https://static.arxiv.org/static/base/1.0.0a5/js/notification.js\"></script>\\n\\n    \\n  <link rel=\"stylesheet\" href=\"https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css\" />\\n  <link rel=\"stylesheet\" href=\"https://static.arxiv.org/static/search/0.5.6/css/search.css\" />\\n  <script\\n    src=\"https://code.jquery.com/jquery-3.2.1.slim.min.js\"\\n    integrity=\"sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g=\"\\n    crossorigin=\"anonymous\"></script>\\n\\n  <script src=\"https://static.arxiv.org/static/search/0.5.6/js/fieldset.js\"></script>\\n  <style>\\n  radio#cf-customfield_11400 {\\n    display: none;\\n  }\\n  </style>\\n\\n  </head>\\n  <body>\\n  \\n  \\n  <header><a href=\"#main-container\" class=\"is-sr-only\">Skip to main content</a>\\n    \\n    <!-- contains Cornell logo and sponsor statement -->\\n<div class=\"attribution level is-marginless\" role=\"banner\">\\n  <div class=\"level-left\">\\n    <a class=\"level-item\" href=\"https://cornell.edu/\"><img src=\"https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg\" alt=\"Cornell University\" width=\"200\" aria-label=\"logo\" /></a>\\n  </div>\\n  <div class=\"level-right is-marginless\"><p class=\"sponsors level-item is-marginless\"><a href=\"https://arxiv.org/about/ourmembers\">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a></p></div>\\n</div>\\n<!-- contains arXiv identity and search bar -->\\n<div class=\"identity level is-marginless\">\\n  <div class=\"level-left\">\\n    <div class=\"level-item\">\\n      <a class=\"arxiv\" href=\"https://arxiv.org/\" aria-label=\"arxiv-logo\">\\n        <img src=\"https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg\" aria-label=\"logo\" alt=\"arxiv logo\" width=\"85\" style=\"width:85px;\"/>\\n      </a>\\n    </div>\\n  </div>\\n  \\n  <div class=\"search-block level-right\">\\n    <form class=\"level-item mini-search\" method=\"GET\" action=\"https://arxiv.org/search\">\\n      <div class=\"field has-addons\">\\n        <div class=\"control\">\\n          <input class=\"input is-small\" type=\"text\" name=\"query\" placeholder=\"Search...\" aria-label=\"Search term or terms\" />\\n          <p class=\"help\"><a href=\"https://arxiv.org/help\">Help</a> | <a href=\"https://arxiv.org/search/advanced\">Advanced Search</a></p>\\n        </div>\\n        <div class=\"control\">\\n          <div class=\"select is-small\">\\n            <select name=\"searchtype\" aria-label=\"Field to search\">\\n              <option value=\"all\" selected=\"selected\">All fields</option>\\n              <option value=\"title\">Title</option>\\n              <option value=\"author\">Author</option>\\n              <option value=\"abstract\">Abstract</option>\\n              <option value=\"comments\">Comments</option>\\n              <option value=\"journal_ref\">Journal reference</option>\\n              <option value=\"acm_class\">ACM classification</option>\\n              <option value=\"msc_class\">MSC classification</option>\\n              <option value=\"report_num\">Report number</option>\\n              <option value=\"paper_id\">arXiv identifier</option>\\n              <option value=\"doi\">DOI</option>\\n              <option value=\"orcid\">ORCID</option>\\n              <option value=\"author_id\">arXiv author ID</option>\\n              <option value=\"help\">Help pages</option>\\n              <option value=\"full_text\">Full text</option>\\n            </select>\\n          </div>\\n        </div>\\n        <input type=\"hidden\" name=\"source\" value=\"header\">\\n        <button class=\"button is-small is-cul-darker\">Search</button>\\n      </div>\\n    </form>\\n  </div>\\n</div> <!-- closes identity -->\\n\\n<div class=\"container\">\\n    <div class=\"user-tools is-size-7 has-text-right has-text-weight-bold\" role=\"navigation\" aria-label=\"User menu\">\\n      <a href=\"https://arxiv.org/login\">Login</a>\\n    </div>\\n</div>\\n    \\n  </header>\\n  <main class=\"container\" id=\"main-container\">\\n    \\n\\n\\n    \\n  <div class=\"level is-marginless\">\\n    <div class=\"level-left\">\\n      <h1 class=\"title is-clearfix\">\\n    \\n        Showing 1&ndash;50 of 548,826 results\\n    \\n</h1>\\n    </div>\\n    <div class=\"level-right is-hidden-mobile\">\\n      <!-- feedback for mobile is moved to footer -->\\n      <span class=\"help\" style=\"display: inline-block;\"><a href=\"https://github.com/arXiv/arxiv-search/releases\">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>\\n      <button class=\"button is-small\" id=\"feedback-button\">Feedback?</button>\\n    </div>\\n  </div>\\n    <div class=\"content\">\\n      \\n  \\n    \\n\\n    <div class=\"columns\">\\n      <div class=\"column is-two-thirds-tablet\">\\n        <p style=\"margin-bottom: .5em\">Query: <a href=\"/search/advanced?terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=0\">order: -announced_date_first; size: 50; classification: Computer Science (cs); include_cross_list: True</a></p>\\n        <div class=\"buttons\">\\n          <a class=\"button is-link\" href=\"/search/advanced?terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=0\">Refine query</a><a class=\"button\" href=\"/search/advanced\">New search</a>\\n        </div>\\n      </div>\\n      <div class=\"column is-one-third-tablet is-hidden-mobile\">\\n        <p class=\"has-text-right\" style=\"margin-top: 1em\">\\n          \\n          <a href=\"/search/?order=-announced_date_first&amp;size=50\">Simple Search</a>\\n          \\n        </p>\\n      </div>\\n    </div>\\n\\n    \\n        \\n<div class=\"level breathe-horizontal\">\\n  <div class=\"level-left\">\\n    <form method=\"GET\" action=\"/search/advanced\">\\n      <div style=\"display: none;\">\\n        \\n          \\n            <input id=\"advanced\" name=\"advanced\" type=\"hidden\" value=\"\">\\n          \\n        \\n          \\n            <ul id=\"terms\"><li><label for=\"terms-0\">Terms-0</label> <table id=\"terms-0\"><tr><th><label for=\"terms-0-term\">Search term...</label></th><td><input id=\"terms-0-term\" name=\"terms-0-term\" type=\"text\" value=\"\"></td></tr><tr><th><label for=\"terms-0-operator\">Operator</label></th><td><select id=\"terms-0-operator\" name=\"terms-0-operator\"><option selected value=\"AND\">AND</option><option value=\"OR\">OR</option><option value=\"NOT\">NOT</option></select></td></tr><tr><th><label for=\"terms-0-field\">Field</label></th><td><select id=\"terms-0-field\" name=\"terms-0-field\"><option selected value=\"title\">Title</option><option value=\"author\">Author(s)</option><option value=\"abstract\">Abstract</option><option value=\"comments\">Comments</option><option value=\"journal_ref\">Journal reference</option><option value=\"acm_class\">ACM classification</option><option value=\"msc_class\">MSC classification</option><option value=\"report_num\">Report number</option><option value=\"paper_id\">arXiv identifier</option><option value=\"cross_list_category\">Cross-list category</option><option value=\"doi\">DOI</option><option value=\"orcid\">ORCID</option><option value=\"author_id\">arXiv author ID</option><option value=\"all\">All fields</option></select></td></tr></table></li></ul>\\n          \\n        \\n          \\n            <table id=\"classification\"><tr><th><label for=\"classification-computer_science\">Computer Science (cs)</label></th><td><input checked id=\"classification-computer_science\" name=\"classification-computer_science\" type=\"checkbox\" value=\"y\"></td></tr><tr><th><label for=\"classification-economics\">Economics (econ)</label></th><td><input id=\"classification-economics\" name=\"classification-economics\" type=\"checkbox\" value=\"y\"></td></tr><tr><th><label for=\"classification-eess\">Electrical Engineering and Systems Science (eess)</label></th><td><input id=\"classification-eess\" name=\"classification-eess\" type=\"checkbox\" value=\"y\"></td></tr><tr><th><label for=\"classification-mathematics\">Mathematics (math)</label></th><td><input id=\"classification-mathematics\" name=\"classification-mathematics\" type=\"checkbox\" value=\"y\"></td></tr><tr><th><label for=\"classification-physics\">Physics</label></th><td><input id=\"classification-physics\" name=\"classification-physics\" type=\"checkbox\" value=\"y\"></td></tr><tr><th><label for=\"classification-physics_archives\">Physics Archives</label></th><td><select id=\"classification-physics_archives\" name=\"classification-physics_archives\"><option selected value=\"all\">all</option><option value=\"astro-ph\">astro-ph</option><option value=\"cond-mat\">cond-mat</option><option value=\"gr-qc\">gr-qc</option><option value=\"hep-ex\">hep-ex</option><option value=\"hep-lat\">hep-lat</option><option value=\"hep-ph\">hep-ph</option><option value=\"hep-th\">hep-th</option><option value=\"math-ph\">math-ph</option><option value=\"nlin\">nlin</option><option value=\"nucl-ex\">nucl-ex</option><option value=\"nucl-th\">nucl-th</option><option value=\"physics\">physics</option><option value=\"quant-ph\">quant-ph</option></select></td></tr><tr><th><label for=\"classification-q_biology\">Quantitative Biology (q-bio)</label></th><td><input id=\"classification-q_biology\" name=\"classification-q_biology\" type=\"checkbox\" value=\"y\"></td></tr><tr><th><label for=\"classification-q_finance\">Quantitative Finance (q-fin)</label></th><td><input id=\"classification-q_finance\" name=\"classification-q_finance\" type=\"checkbox\" value=\"y\"></td></tr><tr><th><label for=\"classification-statistics\">Statistics (stat)</label></th><td><input id=\"classification-statistics\" name=\"classification-statistics\" type=\"checkbox\" value=\"y\"></td></tr><tr><th><label for=\"classification-include_cross_list\">Include cross-list</label></th><td><ul id=\"classification-include_cross_list\"><li><input checked id=\"classification-include_cross_list-0\" name=\"classification-include_cross_list\" type=\"radio\" value=\"include\"> <label for=\"classification-include_cross_list-0\">Include cross-listed papers</label></li><li><input id=\"classification-include_cross_list-1\" name=\"classification-include_cross_list\" type=\"radio\" value=\"exclude\"> <label for=\"classification-include_cross_list-1\">Exclude cross-listed papers</label></li></ul></td></tr></table>\\n          \\n        \\n          \\n            <table id=\"date\"><tr><th><label for=\"date-filter_by\">Filter by</label></th><td><ul id=\"date-filter_by\"><li><input checked id=\"date-filter_by-0\" name=\"date-filter_by\" type=\"radio\" value=\"all_dates\"> <label for=\"date-filter_by-0\">All dates</label></li><li><input id=\"date-filter_by-1\" name=\"date-filter_by\" type=\"radio\" value=\"past_12\"> <label for=\"date-filter_by-1\">Past 12 months</label></li><li><input id=\"date-filter_by-2\" name=\"date-filter_by\" type=\"radio\" value=\"specific_year\"> <label for=\"date-filter_by-2\">Specific year</label></li><li><input id=\"date-filter_by-3\" name=\"date-filter_by\" type=\"radio\" value=\"date_range\"> <label for=\"date-filter_by-3\">Date range</label></li></ul></td></tr><tr><th><label for=\"date-year\">Year</label></th><td><input id=\"date-year\" name=\"date-year\" type=\"text\" value=\"\"></td></tr><tr><th><label for=\"date-from_date\">From</label></th><td><input id=\"date-from_date\" name=\"date-from_date\" type=\"text\" value=\"\"></td></tr><tr><th><label for=\"date-to_date\">to</label></th><td><input id=\"date-to_date\" name=\"date-to_date\" type=\"text\" value=\"\"></td></tr><tr><th><label for=\"date-date_type\">Apply to</label></th><td><ul id=\"date-date_type\"><li><input checked id=\"date-date_type-0\" name=\"date-date_type\" type=\"radio\" value=\"submitted_date\"> <label for=\"date-date_type-0\">Submission date (most recent)</label></li><li><input id=\"date-date_type-1\" name=\"date-date_type\" type=\"radio\" value=\"submitted_date_first\"> <label for=\"date-date_type-1\">Submission date (original)</label></li><li><input id=\"date-date_type-2\" name=\"date-date_type\" type=\"radio\" value=\"announced_date_first\"> <label for=\"date-date_type-2\">Announcement date</label></li></ul></td></tr></table>\\n          \\n        \\n          \\n        \\n          \\n        \\n          \\n            <input id=\"include_older_versions\" name=\"include_older_versions\" type=\"checkbox\" value=\"y\">\\n          \\n        \\n          \\n            <ul id=\"abstracts\"><li><input checked id=\"abstracts-0\" name=\"abstracts\" type=\"radio\" value=\"show\"> <label for=\"abstracts-0\">Show abstracts</label></li><li><input id=\"abstracts-1\" name=\"abstracts\" type=\"radio\" value=\"hide\"> <label for=\"abstracts-1\">Hide abstracts</label></li></ul>\\n          \\n        \\n      </div>\\n      <div class=\"box field is-grouped is-grouped-multiline level-item\">\\n        <div class=\"control\">\\n          <span class=\"select is-small\">\\n            <select id=\"size\" name=\"size\"><option value=\"25\">25</option><option selected value=\"50\">50</option><option value=\"100\">100</option><option value=\"200\">200</option></select>\\n          </span>\\n          <label for=\"size\">results per page</label>.\\n        </div>\\n        <div class=\"control\">\\n          <label for=\"order\">Sort results by</label>\\n          <span class=\"select is-small\">\\n            <select id=\"order\" name=\"order\"><option selected value=\"-announced_date_first\">Announcement date (newest first)</option><option value=\"announced_date_first\">Announcement date (oldest first)</option><option value=\"-submitted_date\">Submission date (newest first)</option><option value=\"submitted_date\">Submission date (oldest first)</option><option value=\"\">Relevance</option></select>\\n          </span>\\n        </div>\\n        <div class=\"control\">\\n          <button class=\"button is-small is-link\">Go</button>\\n        </div>\\n      </div>\\n    </form>\\n  </div>\\n</div>\\n        \\n\\n\\n  <nav class=\"pagination is-small is-centered breathe-horizontal\" role=\"navigation\" aria-label=\"pagination\">\\n    \\n    <a href=\"\"\\n      class=\"pagination-previous is-invisible\">Previous\\n    </a>\\n    \\n    \\n      <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=50\"\\n        class=\"pagination-next\" >Next\\n      </a>\\n    \\n    <ul class=\"pagination-list\">\\n\\n      <li>\\n        <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=0\"\\n          class=\"pagination-link is-current\"\\n          aria-label=\"Goto page 1\">1\\n        </a>\\n      </li>\\n\\n      \\n                                     \\n          \\n          <li>\\n            <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=50\"\\n              class=\"pagination-link \"\\n              aria-label=\"Page 2\"\\n              aria-current=\"page\">2\\n            </a>\\n          </li>\\n          \\n          <li>\\n            <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=100\"\\n              class=\"pagination-link \"\\n              aria-label=\"Page 3\"\\n              aria-current=\"page\">3\\n            </a>\\n          </li>\\n          \\n          <li>\\n            <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=150\"\\n              class=\"pagination-link \"\\n              aria-label=\"Page 4\"\\n              aria-current=\"page\">4\\n            </a>\\n          </li>\\n          \\n          <li>\\n            <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=200\"\\n              class=\"pagination-link \"\\n              aria-label=\"Page 5\"\\n              aria-current=\"page\">5\\n            </a>\\n          </li>\\n          \\n          <li><span class=\"pagination-ellipsis\">&hellip;</span></li>\\n        \\n      \\n    </ul>\\n  </nav>\\n  \\n\\n\\n\\n<ol class=\"breathe-horizontal\" start=\"1\"> \\n\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05336\">arXiv:2401.05336</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05336\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05336\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Towards Online Sign Language Recognition and Translation\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Zuo%2C+R\">Ronglai Zuo</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Wei%2C+F\">Fangyun Wei</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Mak%2C+B\">Brian Mak</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05336v1-abstract-short\" style=\"display: inline;\">\\n        The objective of sign language recognition is to bridge the communication gap between the deaf and the hearing. Numerous previous works train their models using the well-established connectionist temporal classification (CTC) loss. During the inference stage, the CTC-based models typically take the entire sign video as input to make predictions. This type of inference scheme is referred to as offl&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05336v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05336v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05336v1-abstract-full\" style=\"display: none;\">\\n        The objective of sign language recognition is to bridge the communication gap between the deaf and the hearing. Numerous previous works train their models using the well-established connectionist temporal classification (CTC) loss. During the inference stage, the CTC-based models typically take the entire sign video as input to make predictions. This type of inference scheme is referred to as offline recognition. In contrast, while mature speech recognition systems can efficiently recognize spoken words on the fly, sign language recognition still falls short due to the lack of practical online solutions. In this work, we take the first step towards filling this gap. Our approach comprises three phases: 1) developing a sign language dictionary encompassing all glosses present in a target sign language dataset; 2) training an isolated sign language recognition model on augmented signs using both conventional classification loss and our novel saliency loss; 3) employing a sliding window approach on the input sign sequence and feeding each sign clip to the well-optimized model for online recognition. Furthermore, our online recognition model can be extended to boost the performance of any offline model, and to support online translation by appending a gloss-to-text network onto the recognition model. By integrating our online framework with the previously best-performing offline model, TwoStream-SLR, we achieve new state-of-the-art performance on three benchmarks: Phoenix-2014, Phoenix-2014T, and CSL-Daily. Code and models will be available at https://github.com/FangyunWei/SLRT\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05336v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05336v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05335\">arXiv:2401.05335</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05335\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05335\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Graphics\">cs.GR</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Shahbazi%2C+M\">Mohamad Shahbazi</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Claessens%2C+L\">Liesbeth Claessens</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Niemeyer%2C+M\">Michael Niemeyer</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Collins%2C+E\">Edo Collins</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Tonioni%2C+A\">Alessio Tonioni</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Van+Gool%2C+L\">Luc Van Gool</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Tombari%2C+F\">Federico Tombari</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05335v1-abstract-short\" style=\"display: inline;\">\\n        We introduce InseRF, a novel method for generative object insertion in the NeRF reconstructions of 3D scenes. Based on a user-provided textual description and a 2D bounding box in a reference viewpoint, InseRF generates new objects in 3D scenes. Recently, methods for 3D scene editing have been profoundly transformed, owing to the use of strong priors of text-to-image diffusion models in 3D generat&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05335v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05335v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05335v1-abstract-full\" style=\"display: none;\">\\n        We introduce InseRF, a novel method for generative object insertion in the NeRF reconstructions of 3D scenes. Based on a user-provided textual description and a 2D bounding box in a reference viewpoint, InseRF generates new objects in 3D scenes. Recently, methods for 3D scene editing have been profoundly transformed, owing to the use of strong priors of text-to-image diffusion models in 3D generative modeling. Existing methods are mostly effective in editing 3D scenes via style and appearance changes or removing existing objects. Generating new objects, however, remains a challenge for such methods, which we address in this study. Specifically, we propose grounding the 3D object insertion to a 2D object insertion in a reference view of the scene. The 2D edit is then lifted to 3D using a single-view object reconstruction method. The reconstructed object is then inserted into the scene, guided by the priors of monocular depth estimation methods. We evaluate our method on various 3D scenes and provide an in-depth analysis of the proposed components. Our experiments with generative insertion of objects in several 3D scenes indicate the effectiveness of our method compared to the existing methods. InseRF is capable of controllable and 3D-consistent object insertion without requiring explicit 3D information as input. Please visit our project page at https://mohamad-shahbazi.github.io/inserf.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05335v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05335v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05334\">arXiv:2401.05334</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05334\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05334\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Graphics\">cs.GR</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        URHand: Universal Relightable Hands\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Chen%2C+Z\">Zhaoxi Chen</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Moon%2C+G\">Gyeongsik Moon</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Guo%2C+K\">Kaiwen Guo</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Cao%2C+C\">Chen Cao</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Pidhorskyi%2C+S\">Stanislav Pidhorskyi</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Simon%2C+T\">Tomas Simon</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Joshi%2C+R\">Rohan Joshi</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Dong%2C+Y\">Yuan Dong</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Xu%2C+Y\">Yichen Xu</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Pires%2C+B\">Bernardo Pires</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Wen%2C+H\">He Wen</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Evans%2C+L\">Lucas Evans</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Peng%2C+B\">Bo Peng</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Buffalini%2C+J\">Julia Buffalini</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Trimble%2C+A\">Autumn Trimble</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=McPhail%2C+K\">Kevyn McPhail</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Schoeller%2C+M\">Melissa Schoeller</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Yu%2C+S\">Shoou-I Yu</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Romero%2C+J\">Javier Romero</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Zollh%C3%B6fer%2C+M\">Michael Zollh\\xc3\\xb6fer</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Sheikh%2C+Y\">Yaser Sheikh</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+Z\">Ziwei Liu</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Saito%2C+S\">Shunsuke Saito</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05334v1-abstract-short\" style=\"display: inline;\">\\n        Existing photorealistic relightable hand models require extensive identity-specific observations in different views, poses, and illuminations, and face challenges in generalizing to natural illuminations and novel identities. To bridge this gap, we present URHand, the first universal relightable hand model that generalizes across viewpoints, poses, illuminations, and identities. Our model allows f&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05334v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05334v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05334v1-abstract-full\" style=\"display: none;\">\\n        Existing photorealistic relightable hand models require extensive identity-specific observations in different views, poses, and illuminations, and face challenges in generalizing to natural illuminations and novel identities. To bridge this gap, we present URHand, the first universal relightable hand model that generalizes across viewpoints, poses, illuminations, and identities. Our model allows few-shot personalization using images captured with a mobile phone, and is ready to be photorealistically rendered under novel illuminations. To simplify the personalization process while retaining photorealism, we build a powerful universal relightable prior based on neural relighting from multi-view images of hands captured in a light stage with hundreds of identities. The key challenge is scaling the cross-identity training while maintaining personalized fidelity and sharp details without compromising generalization under natural illuminations. To this end, we propose a spatially varying linear lighting model as the neural renderer that takes physics-inspired shading as input feature. By removing non-linear activations and bias, our specifically designed lighting model explicitly keeps the linearity of light transport. This enables single-stage training from light-stage data while generalizing to real-time rendering under arbitrary continuous illuminations across diverse identities. In addition, we introduce the joint learning of a physically based model and our neural relighting model, which further improves fidelity and generalization. Extensive experiments show that our approach achieves superior performance over existing methods in terms of both quality and generalizability. We also demonstrate quick personalization of URHand from a short phone scan of an unseen identity.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05334v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05334v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Project Page https://frozenburning.github.io/projects/urhand/</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05329\">arXiv:2401.05329</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05329\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05329\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Networking and Internet Architecture\">cs.NI</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        \\\\textit{SmartMME}: Implementation of Base Station Switching Off Strategy in ns-3\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Sen%2C+A\">Argha Sen</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Pal%2C+B\">Bhupendra Pal</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Achari%2C+S\">Seemant Achari</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Chakraborty%2C+S\">Sandip Chakraborty</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05329v1-abstract-short\" style=\"display: inline;\">\\n        In the landscape of next-generation cellular networks, a projected surge of over 12 billion subscriptions foreshadows a considerable upswing in the network&#39;s overall energy consumption. The proliferation of User Equipment (UE) drives this energy demand, urging 5G deployments to seek more energy-efficient methodologies. In this work, we propose SmartMME, as a pivotal solution aimed at optimizing Ba&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05329v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05329v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05329v1-abstract-full\" style=\"display: none;\">\\n        In the landscape of next-generation cellular networks, a projected surge of over 12 billion subscriptions foreshadows a considerable upswing in the network&#39;s overall energy consumption. The proliferation of User Equipment (UE) drives this energy demand, urging 5G deployments to seek more energy-efficient methodologies. In this work, we propose SmartMME, as a pivotal solution aimed at optimizing Base Station (BS) energy usage. By harnessing and analyzing critical network states-such as UE connections, data traffic at individual UEs, and other pertinent metrics-our methodology intelligently orchestrates the BS&#39;s power states, making informed decisions on when to activate or deactivate the BS. This meticulous approach significantly curtails the network&#39;s overall energy consumption. In a bid to validate its efficiency, we seamlessly integrated our module into Network Simulator-3 (ns-3), conducting extensive testing to demonstrate its prowess in effectively managing and reducing net energy consumption. As advocates of collaborative progress, we&#39;ve opted to open-source this module, inviting the engagement and feedback of the wider research community on GitHub.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05329v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05329v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05322\">arXiv:2401.05322</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05322\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05322\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Arrival Time Prediction for Autonomous Shuttle Services in the Real World: Evidence from Five Cities\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Schmidt%2C+C\">Carolin Schmidt</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Tygesen%2C+M\">Mathias Tygesen</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Rodrigues%2C+F\">Filipe Rodrigues</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05322v1-abstract-short\" style=\"display: inline;\">\\n        Urban mobility is on the cusp of transformation with the emergence of shared, connected, and cooperative automated vehicles. Yet, for them to be accepted by customers, trust in their punctuality is vital. Many pilot initiatives operate without a fixed schedule, thus enhancing the importance of reliable arrival time (AT) predictions. This study presents an AT prediction system for autonomous shuttl&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05322v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05322v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05322v1-abstract-full\" style=\"display: none;\">\\n        Urban mobility is on the cusp of transformation with the emergence of shared, connected, and cooperative automated vehicles. Yet, for them to be accepted by customers, trust in their punctuality is vital. Many pilot initiatives operate without a fixed schedule, thus enhancing the importance of reliable arrival time (AT) predictions. This study presents an AT prediction system for autonomous shuttles, utilizing separate models for dwell and running time predictions, validated on real-world data from five cities. Alongside established methods such as XGBoost, we explore the benefits of integrating spatial data using graph neural networks (GNN). To accurately handle the case of a shuttle bypassing a stop, we propose a hierarchical model combining a random forest classifier and a GNN. The results for the final AT prediction are promising, showing low errors even when predicting several stops ahead. Yet, no single model emerges as universally superior, and we provide insights into the characteristics of pilot sites that influence the model selection process. Finally, we identify dwell time prediction as the key determinant in overall AT prediction accuracy when autonomous shuttles are deployed in low-traffic areas or under regulatory speed limits. This research provides insights into the current state of autonomous public transport prediction models and paves the way for more data-informed decision-making as the field advances.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05322v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05322v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05321\">arXiv:2401.05321</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05321\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05321\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computational Complexity\">cs.CC</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Quantum Physics\">quant-ph</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Quantum Time-Space Tradeoffs for Matrix Problems\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Beame%2C+P\">Paul Beame</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Kornerup%2C+N\">Niels Kornerup</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05321v1-abstract-short\" style=\"display: inline;\">\\n        We consider the time and space required for quantum computers to solve a wide variety of problems involving matrices, many of which have only been analyzed classically in prior work. Our main results show that for a range of linear algebra problems -- including matrix-vector product, matrix inversion, matrix multiplication and powering -- existing classical time-space tradeoffs, several of which a&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05321v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05321v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05321v1-abstract-full\" style=\"display: none;\">\\n        We consider the time and space required for quantum computers to solve a wide variety of problems involving matrices, many of which have only been analyzed classically in prior work. Our main results show that for a range of linear algebra problems -- including matrix-vector product, matrix inversion, matrix multiplication and powering -- existing classical time-space tradeoffs, several of which are tight for every space bound, also apply to quantum algorithms. For example, for almost all matrices $A$, including the discrete Fourier transform (DFT) matrix, we prove that quantum circuits with at most $T$ input queries and $S$ qubits of memory require $T=\\xce\\xa9(n^2/S)$ to compute matrix-vector product $Ax$ for $x \\\\in \\\\{0,1\\\\}^n$. We similarly prove that matrix multiplication for $n\\\\times n$ binary matrices requires $T=\\xce\\xa9(n^3 / \\\\sqrt{S})$. Because many of our lower bounds match deterministic algorithms with the same time and space complexity, we show that quantum computers cannot provide any asymptotic advantage for these problems with any space bound. We obtain matching lower bounds for the stronger notion of quantum cumulative memory complexity -- the sum of the space per layer of a circuit.\\n  We also consider Boolean (i.e. AND-OR) matrix multiplication and matrix-vector products, improving the previous quantum time-space tradeoff lower bounds for $n\\\\times n$ Boolean matrix multiplication to $T=\\xce\\xa9(n^{2.5}/S^{1/3})$ from $T=\\xce\\xa9(n^{2.5}/S^{1/2})$.\\n  Our improved lower bound for Boolean matrix multiplication is based on a new coloring argument that extracts more from the strong direct product theorem used in prior work. Our tight lower bounds for linear algebra problems require adding a new bucketing method to the recording-query technique of Zhandry that lets us apply classical arguments to upper bound the success probability of quantum circuits.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05321v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05321v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">36 pages, 1 figure</span>\\n    </p>\\n    \\n\\n    \\n      <p class=\"comments is-size-7\">\\n        \\n\\n        \\n          <span class=\"has-text-black-bis has-text-weight-semibold\">MSC Class:</span>\\n          68Q17\\n        \\n\\n        \\n          <span class=\"has-text-black-bis has-text-weight-semibold\">ACM Class:</span>\\n          F.2.3\\n        \\n      </p>\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05319\">arXiv:2401.05319</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05319\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05319\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Software Engineering\">cs.SE</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Leveraging Print Debugging to Improve Code Generation in Large Language Models\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Hu%2C+X\">Xueyu Hu</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Kuang%2C+K\">Kun Kuang</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Sun%2C+J\">Jiankai Sun</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Yang%2C+H\">Hongxia Yang</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Wu%2C+F\">Fei Wu</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05319v1-abstract-short\" style=\"display: inline;\">\\n        Large language models (LLMs) have made significant progress in code generation tasks, but their performance in tackling programming problems with complex data structures and algorithms remains suboptimal. To address this issue, we propose an in-context learning approach that guides LLMs to debug by using a &#34;print debugging&#34; method, which involves inserting print statements to trace and analysing l&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05319v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05319v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05319v1-abstract-full\" style=\"display: none;\">\\n        Large language models (LLMs) have made significant progress in code generation tasks, but their performance in tackling programming problems with complex data structures and algorithms remains suboptimal. To address this issue, we propose an in-context learning approach that guides LLMs to debug by using a &#34;print debugging&#34; method, which involves inserting print statements to trace and analysing logs for fixing the bug. We collect a Leetcode problem dataset and evaluate our method using the Leetcode online judging system. Experiments with GPT-4 demonstrate the effectiveness of our approach, outperforming rubber duck debugging in easy and medium-level Leetcode problems by 1.5% and 17.9%.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05319v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05319v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05318\">arXiv:2401.05318</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05318\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05318\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Robotics\">cs.RO</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Analytical Model and Experimental Testing of the SoftFoot: an Adaptive Robot Foot for Walking over Obstacles and Irregular Terrains\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Piazza%2C+C\">Cristina Piazza</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Della+Santina%2C+C\">Cosimo Della Santina</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Catalano%2C+M+G\">Manuel G. Catalano</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Grioli%2C+G\">Giorgio Grioli</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Bicchi%2C+A\">Antonio Bicchi</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05318v1-abstract-short\" style=\"display: inline;\">\\n        Robot feet are crucial for maintaining dynamic stability and propelling the body during walking, especially on uneven terrains. Traditionally, robot feet were mostly designed as flat and stiff pieces of metal, which meets its limitations when the robot is required to step on irregular grounds, e.g. stones. While one could think that adding compliance under such feet would solve the problem, this i&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05318v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05318v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05318v1-abstract-full\" style=\"display: none;\">\\n        Robot feet are crucial for maintaining dynamic stability and propelling the body during walking, especially on uneven terrains. Traditionally, robot feet were mostly designed as flat and stiff pieces of metal, which meets its limitations when the robot is required to step on irregular grounds, e.g. stones. While one could think that adding compliance under such feet would solve the problem, this is not the case. To address this problem, we introduced the SoftFoot, an adaptive foot design that can enhance walking performance over irregular grounds. The proposed design is completely passive and varies its shape and stiffness based on the exerted forces, through a system of pulley, tendons, and springs opportunely placed in the structure. This paper outlines the motivation behind the SoftFoot and describes the theoretical model which led to its final design. The proposed system has been experimentally tested and compared with two analogous conventional feet, a rigid one and a compliant one, with similar footprints and soles. The experimental validation focuses on the analysis of the standing performance, measured in terms of the equivalent support surface extension and the compensatory ankle angle, and the rejection of impulsive forces, which is important in events such as stepping on unforeseen obstacles. Results show that the SoftFoot has the largest equivalent support surface when standing on obstacles, and absorbs impulsive loads in a way almost as good as a compliant foot.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05318v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05318v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05314\">arXiv:2401.05314</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05314\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05314\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Audio and Speech Processing\">eess.AS</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Sound\">cs.SD</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Cai%2C+K\">Kevin Cai</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+C\">Chonghua Liu</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Chan%2C+D+M\">David M. Chan</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05314v1-abstract-short\" style=\"display: inline;\">\\n        The Internet&#39;s wealth of content, with up to 60% published in English, starkly contrasts the global population, where only 18.8% are English speakers, and just 5.1% consider it their native language, leading to disparities in online information access. Unfortunately, automated processes for dubbing of video - replacing the audio track of a video with a translated alternative - remains a complex an&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05314v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05314v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05314v1-abstract-full\" style=\"display: none;\">\\n        The Internet&#39;s wealth of content, with up to 60% published in English, starkly contrasts the global population, where only 18.8% are English speakers, and just 5.1% consider it their native language, leading to disparities in online information access. Unfortunately, automated processes for dubbing of video - replacing the audio track of a video with a translated alternative - remains a complex and challenging task due to pipelines, necessitating precise timing, facial movement synchronization, and prosody matching. While end-to-end dubbing offers a solution, data scarcity continues to impede the progress of both end-to-end and pipeline-based methods. In this work, we introduce Anim-400K, a comprehensive dataset of over 425K aligned animated video segments in Japanese and English supporting various video-related tasks, including automated dubbing, simultaneous translation, guided video summarization, and genre/theme/style classification. Our dataset is made publicly available for research purposes at https://github.com/davidmchan/Anim400K.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05314v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05314v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">To appear in ICASSP 2024</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05308\">arXiv:2401.05308</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05308\">pdf</a>, <a href=\"https://arxiv.org/ps/2401.05308\">ps</a>, <a href=\"https://arxiv.org/format/2401.05308\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Networking and Internet Architecture\">cs.NI</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Strategic Client Selection to Address Non-IIDness in HAPS-enabled FL Networks\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Farajzadeh%2C+A\">Amin Farajzadeh</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Yadav%2C+A\">Animesh Yadav</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Yanikomeroglu%2C+H\">Halim Yanikomeroglu</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05308v1-abstract-short\" style=\"display: inline;\">\\n        The deployment of federated learning (FL) within vertical heterogeneous networks, such as those enabled by high-altitude platform station (HAPS), offers the opportunity to engage a wide array of clients, each endowed with distinct communication and computational capabilities. This diversity not only enhances the training accuracy of FL models but also hastens their convergence. Yet, applying FL in&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05308v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05308v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05308v1-abstract-full\" style=\"display: none;\">\\n        The deployment of federated learning (FL) within vertical heterogeneous networks, such as those enabled by high-altitude platform station (HAPS), offers the opportunity to engage a wide array of clients, each endowed with distinct communication and computational capabilities. This diversity not only enhances the training accuracy of FL models but also hastens their convergence. Yet, applying FL in these expansive networks presents notable challenges, particularly the significant non-IIDness in client data distributions. Such data heterogeneity often results in slower convergence rates and reduced effectiveness in model training performance. Our study introduces a client selection strategy tailored to address this issue, leveraging user network traffic behaviour. This strategy involves the prediction and classification of clients based on their network usage patterns while prioritizing user privacy. By strategically selecting clients whose data exhibit similar patterns for participation in FL training, our approach fosters a more uniform and representative data distribution across the network. Our simulations demonstrate that this targeted client selection methodology significantly reduces the training loss of FL models in HAPS networks, thereby effectively tackling a crucial challenge in implementing large-scale FL systems.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05308v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05308v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Submitted to IEEE for possible publication</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05304\">arXiv:2401.05304</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05304\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05304\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computers and Society\">cs.CY</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Can Probabilistic Feedback Drive User Impacts in Online Platforms?\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Dai%2C+J\">Jessica Dai</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Flanigan%2C+B\">Bailey Flanigan</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Haghtalab%2C+N\">Nika Haghtalab</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Jagadeesan%2C+M\">Meena Jagadeesan</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Podimata%2C+C\">Chara Podimata</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05304v1-abstract-short\" style=\"display: inline;\">\\n        A common explanation for negative user impacts of content recommender systems is misalignment between the platform&#39;s objective and user welfare. In this work, we show that misalignment in the platform&#39;s objective is not the only potential cause of unintended impacts on users: even when the platform&#39;s objective is fully aligned with user welfare, the platform&#39;s learning algorithm can induce negativ&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05304v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05304v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05304v1-abstract-full\" style=\"display: none;\">\\n        A common explanation for negative user impacts of content recommender systems is misalignment between the platform&#39;s objective and user welfare. In this work, we show that misalignment in the platform&#39;s objective is not the only potential cause of unintended impacts on users: even when the platform&#39;s objective is fully aligned with user welfare, the platform&#39;s learning algorithm can induce negative downstream impacts on users. The source of these user impacts is that different pieces of content may generate observable user reactions (feedback information) at different rates; these feedback rates may correlate with content properties, such as controversiality or demographic similarity of the creator, that affect the user experience. Since differences in feedback rates can impact how often the learning algorithm engages with different content, the learning algorithm may inadvertently promote content with certain such properties. Using the multi-armed bandit framework with probabilistic feedback, we examine the relationship between feedback rates and a learning algorithm&#39;s engagement with individual arms for different no-regret algorithms. We prove that no-regret algorithms can exhibit a wide range of dependencies: if the feedback rate of an arm increases, some no-regret algorithms engage with the arm more, some no-regret algorithms engage with the arm less, and other no-regret algorithms engage with the arm approximately the same number of times. From a platform design perspective, our results highlight the importance of looking beyond regret when measuring an algorithm&#39;s performance, and assessing the nature of a learning algorithm&#39;s engagement with different types of content as well as their resulting downstream impacts.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05304v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05304v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Authors listed in alphabetical order</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05302\">arXiv:2401.05302</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05302\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05302\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Robotics\">cs.RO</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Human-Computer Interaction\">cs.HC</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Verma%2C+M\">Mudit Verma</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Bhambri%2C+S\">Siddhant Bhambri</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Kambhampati%2C+S\">Subbarao Kambhampati</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05302v1-abstract-short\" style=\"display: inline;\">\\n        Large Language Models have shown exceptional generative abilities in various natural language and generation tasks. However, possible anthropomorphization and leniency towards failure cases have propelled discussions on emergent abilities of Large Language Models especially on Theory of Mind (ToM) abilities in Large Language Models. While several false-belief tests exists to verify the ability to&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05302v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05302v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05302v1-abstract-full\" style=\"display: none;\">\\n        Large Language Models have shown exceptional generative abilities in various natural language and generation tasks. However, possible anthropomorphization and leniency towards failure cases have propelled discussions on emergent abilities of Large Language Models especially on Theory of Mind (ToM) abilities in Large Language Models. While several false-belief tests exists to verify the ability to infer and maintain mental models of another entity, we study a special application of ToM abilities that has higher stakes and possibly irreversible consequences : Human Robot Interaction. In this work, we explore the task of Perceived Behavior Recognition, where a robot employs a Large Language Model (LLM) to assess the robot&#39;s generated behavior in a manner similar to human observer. We focus on four behavior types, namely - explicable, legible, predictable, and obfuscatory behavior which have been extensively used to synthesize interpretable robot behaviors. The LLMs goal is, therefore to be a human proxy to the agent, and to answer how a certain agent behavior would be perceived by the human in the loop, for example &#34;Given a robot&#39;s behavior X, would the human observer find it explicable?&#34;. We conduct a human subject study to verify that the users are able to correctly answer such a question in the curated situations (robot setting and plan) across five domains. A first analysis of the belief test yields extremely positive results inflating ones expectations of LLMs possessing ToM abilities. We then propose and perform a suite of perturbation tests which breaks this illusion, i.e. Inconsistent Belief, Uninformative Context and Conviction Test. We conclude that, the high score of LLMs on vanilla prompts showcases its potential use in HRI settings, however to possess ToM demands invariance to trivial or irrelevant perturbations in the context which LLMs lack.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05302v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05302v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Accepted in alt.HRI 2024</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05300\">arXiv:2401.05300</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05300\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05300\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        I am a Strange Dataset: Metalinguistic Tests for Language Models\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Thrush%2C+T\">Tristan Thrush</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Moore%2C+J\">Jared Moore</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Monares%2C+M\">Miguel Monares</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Potts%2C+C\">Christopher Potts</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Kiela%2C+D\">Douwe Kiela</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05300v1-abstract-short\" style=\"display: inline;\">\\n        Statements involving metalinguistic self-reference (&#34;This paper has six sections.&#34;) are prevalent in many domains. Can large language models (LLMs) handle such language? In this paper, we present &#34;I am a Strange Dataset&#34;, a new dataset for addressing this question. There are two subtasks: generation and verification. In generation, models continue statements like &#34;The penultimate word in this sent&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05300v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05300v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05300v1-abstract-full\" style=\"display: none;\">\\n        Statements involving metalinguistic self-reference (&#34;This paper has six sections.&#34;) are prevalent in many domains. Can large language models (LLMs) handle such language? In this paper, we present &#34;I am a Strange Dataset&#34;, a new dataset for addressing this question. There are two subtasks: generation and verification. In generation, models continue statements like &#34;The penultimate word in this sentence is&#34; (where a correct continuation is &#34;is&#34;). In verification, models judge the truth of statements like &#34;The penultimate word in this sentence is sentence.&#34; (false). We also provide minimally different metalinguistic non-self-reference examples to complement the main dataset by probing for whether models can handle metalinguistic language at all. The dataset is hand-crafted by experts and validated by non-expert annotators. We test a variety of open-source LLMs (7B to 70B parameters) as well as closed-source LLMs through APIs. All models perform close to chance across both subtasks and even on the non-self-referential metalinguistic control data, though we find some steady improvement with model scale. GPT 4 is the only model to consistently do significantly better than chance, and it is still only in the 60% range, while our untrained human annotators score well in the 89-93% range. The dataset and evaluation toolkit are available at https://github.com/TristanThrush/i-am-a-strange-dataset.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05300v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05300v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05295\">arXiv:2401.05295</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05295\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05295\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Instrumentation and Detectors\">physics.ins-det</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n          \\n        </div>\\n      \\n        \\n          <div class=\"is-inline-block\" style=\"margin-left: 0.5rem\">\\n            <div class=\"tags has-addons\">\\n              <span class=\"tag is-dark is-size-7\">doi</span>\\n              <span class=\"tag is-light is-size-7\"><a class=\"\" href=\"https://doi.org/10.1016/j.nima.2022.166647\">10.1016/j.nima.2022.166647 <i class=\"fa fa-external-link\" aria-hidden=\"true\"></i></a></span>\\n            </div>\\n          </div>\\n        \\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Synthesis of pulses from particle detectors with a Generative Adversarial Network (GAN)\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Regad%C3%ADo%2C+A\">Alberto Regad\\xc3\\xado</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Esteban%2C+L\">Luis Esteban</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=S%C3%A1nchez-Prieto%2C+S\">Sebasti\\xc3\\xa1n S\\xc3\\xa1nchez-Prieto</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05295v1-abstract-short\" style=\"display: inline;\">\\n        To address the possible lack or total absence of pulses from particle detectors during the development of its associate electronics, we propose a model that can generate them without losing the features of the real ones. This model is based on artificial neural networks, namely Generative Adversarial Networks (GAN). We describe the proposed network architecture, its training methodology and the ap&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05295v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05295v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05295v1-abstract-full\" style=\"display: none;\">\\n        To address the possible lack or total absence of pulses from particle detectors during the development of its associate electronics, we propose a model that can generate them without losing the features of the real ones. This model is based on artificial neural networks, namely Generative Adversarial Networks (GAN). We describe the proposed network architecture, its training methodology and the approach to train the GAN with real pulses from a scintillator receiving radiation from sources of ${}^{137}$Cs and ${}^{22}$Na. The Generator was installed in a Xilinx&#39;s System-On-Chip (SoC). We show how the network is capable of generating pulses with the same shape as the real ones that even match the data distributions in the original pulse-height histogram data.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05295v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05295v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n      <p class=\"comments is-size-7\">\\n        <span class=\"has-text-black-bis has-text-weight-semibold\">Journal ref:</span>\\n        Regad\\xc3\\xado, A., Esteban, L., &amp; S\\xc3\\xa1nchez-Prieto, S. (2022). Synthesis of pulses from particle detectors with a Generative Adversarial Network (GAN). Nuclear Instruments and Methods in Physics Research Section A, 1033, 166647\\n      </p>\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05294\">arXiv:2401.05294</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05294\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05294\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Enhanced Muscle and Fat Segmentation for CT-Based Body Composition Analysis: A Comparative Study\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Hou%2C+B\">Benjamin Hou</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Mathai%2C+T+S\">Tejas Sudharshan Mathai</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+J\">Jianfei Liu</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Parnell%2C+C\">Christopher Parnell</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Summers%2C+R+M\">Ronald M. Summers</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05294v1-abstract-short\" style=\"display: inline;\">\\n        Purpose: Body composition measurements from routine abdominal CT can yield personalized risk assessments for asymptomatic and diseased patients. In particular, attenuation and volume measures of muscle and fat are associated with important clinical outcomes, such as cardiovascular events, fractures, and death. This study evaluates the reliability of an Internal tool for the segmentation of muscle&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05294v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05294v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05294v1-abstract-full\" style=\"display: none;\">\\n        Purpose: Body composition measurements from routine abdominal CT can yield personalized risk assessments for asymptomatic and diseased patients. In particular, attenuation and volume measures of muscle and fat are associated with important clinical outcomes, such as cardiovascular events, fractures, and death. This study evaluates the reliability of an Internal tool for the segmentation of muscle and fat (subcutaneous and visceral) as compared to the well-established public TotalSegmentator tool.\\n  Methods: We assessed the tools across 900 CT series from the publicly available SAROS dataset, focusing on muscle, subcutaneous fat, and visceral fat. The Dice score was employed to assess accuracy in subcutaneous fat and muscle segmentation. Due to the lack of ground truth segmentations for visceral fat, Cohen&#39;s Kappa was utilized to assess segmentation agreement between the tools.\\n  Results: Our Internal tool achieved a 3% higher Dice (83.8 vs. 80.8) for subcutaneous fat and a 5% improvement (87.6 vs. 83.2) for muscle segmentation respectively. A Wilcoxon signed-rank test revealed that our results were statistically different with p&lt;0.01. For visceral fat, the Cohen&#39;s kappa score of 0.856 indicated near-perfect agreement between the two tools. Our internal tool also showed very strong correlations for muscle volume (R^2=0.99), muscle attenuation (R^2=0.93), and subcutaneous fat volume (R^2=0.99) with a moderate correlation for subcutaneous fat attenuation (R^2=0.45).\\n  Conclusion: Our findings indicated that our Internal tool outperformed TotalSegmentator in measuring subcutaneous fat and muscle. The high Cohen&#39;s Kappa score for visceral fat suggests a reliable level of agreement between the two tools. These results demonstrate the potential of our tool in advancing the accuracy of body composition analysis.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05294v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05294v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05293\">arXiv:2401.05293</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05293\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05293\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Score Distillation Sampling with Learned Manifold Corrective\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Alldieck%2C+T\">Thiemo Alldieck</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Kolotouros%2C+N\">Nikos Kolotouros</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Sminchisescu%2C+C\">Cristian Sminchisescu</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05293v1-abstract-short\" style=\"display: inline;\">\\n        Score Distillation Sampling (SDS) is a recent but already widely popular method that relies on an image diffusion model to control optimization problems using text prompts. In this paper, we conduct an in-depth analysis of the SDS loss function, identify an inherent problem with its formulation, and propose a surprisingly easy but effective fix. Specifically, we decompose the loss into different f&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05293v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05293v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05293v1-abstract-full\" style=\"display: none;\">\\n        Score Distillation Sampling (SDS) is a recent but already widely popular method that relies on an image diffusion model to control optimization problems using text prompts. In this paper, we conduct an in-depth analysis of the SDS loss function, identify an inherent problem with its formulation, and propose a surprisingly easy but effective fix. Specifically, we decompose the loss into different factors and isolate the component responsible for noisy gradients. In the original formulation, high text guidance is used to account for the noise, leading to unwanted side effects. Instead, we train a shallow network mimicking the timestep-dependent denoising deficiency of the image diffusion model in order to effectively factor it out. We demonstrate the versatility and the effectiveness of our novel loss formulation through several qualitative and quantitative experiments, including optimization-based image synthesis and editing, zero-shot image translation network training, and text-to-3D synthesis.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05293v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05293v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05290\">arXiv:2401.05290</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05290\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05290\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Robotics\">cs.RO</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Human-Computer Interaction\">cs.HC</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Analysis and Perspectives on the ANA Avatar XPRIZE Competition\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Hauser%2C+K\">Kris Hauser</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Watson%2C+E\">Eleanor Watson</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Bae%2C+J\">Joonbum Bae</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Bankston%2C+J\">Josh Bankston</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Behnke%2C+S\">Sven Behnke</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Borgia%2C+B\">Bill Borgia</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Catalano%2C+M+G\">Manuel G. Catalano</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Dafarra%2C+S\">Stefano Dafarra</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=van+Erp%2C+J+B+F\">Jan B. F. van Erp</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Ferris%2C+T\">Thomas Ferris</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Fishel%2C+J\">Jeremy Fishel</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Hoffman%2C+G\">Guy Hoffman</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Ivaldi%2C+S\">Serena Ivaldi</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Kanehiro%2C+F\">Fumio Kanehiro</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Kheddar%2C+A\">Abderrahmane Kheddar</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Lannuzel%2C+G\">Gaelle Lannuzel</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Morie%2C+J+F\">Jacqueline Ford Morie</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Naughton%2C+P\">Patrick Naughton</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=NGuyen%2C+S\">Steve NGuyen</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Oh%2C+P\">Paul Oh</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Padir%2C+T\">Taskin Padir</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Pippine%2C+J\">Jim Pippine</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Park%2C+J\">Jaeheung Park</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Pucci%2C+D\">Daniele Pucci</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Vaz%2C+J\">Jean Vaz</a>\\n      , et al. (3 additional authors not shown)\\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05290v1-abstract-short\" style=\"display: inline;\">\\n        The ANA Avatar XPRIZE was a four-year competition to develop a robotic &#34;avatar&#34; system to allow a human operator to sense, communicate, and act in a remote environment as though physically present. The competition featured a unique requirement that judges would operate the avatars after less than one hour of training on the human-machine interfaces, and avatar systems were judged on both objective&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05290v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05290v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05290v1-abstract-full\" style=\"display: none;\">\\n        The ANA Avatar XPRIZE was a four-year competition to develop a robotic &#34;avatar&#34; system to allow a human operator to sense, communicate, and act in a remote environment as though physically present. The competition featured a unique requirement that judges would operate the avatars after less than one hour of training on the human-machine interfaces, and avatar systems were judged on both objective and subjective scoring metrics. This paper presents a unified summary and analysis of the competition from technical, judging, and organizational perspectives. We study the use of telerobotics technologies and innovations pursued by the competing teams in their avatar systems, and correlate the use of these technologies with judges&#39; task performance and subjective survey ratings. It also summarizes perspectives from team leads, judges, and organizers about the competition&#39;s execution and impact to inform the future development of telerobotics and telepresence.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05290v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05290v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">26 pages, preprint of article appearing in International Journal of Social Robotics</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05286\">arXiv:2401.05286</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05286\">pdf</a>, <a href=\"https://arxiv.org/ps/2401.05286\">ps</a>, <a href=\"https://arxiv.org/format/2401.05286\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Information Theory\">cs.IT</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Commutative Algebra\">math.AC</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        A class of locally recoverable codes over finite chain rings\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Cavicchioni%2C+G\">Giulia Cavicchioni</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Guerrini%2C+E\">Eleonora Guerrini</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Meneghetti%2C+A\">Alessio Meneghetti</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05286v1-abstract-short\" style=\"display: inline;\">\\n        Locally recoverable codes deal with the task of reconstructing a lost symbol by relying on a portion of the remaining coordinates smaller than an information set. We consider the case of codes over finite chain rings, generalizing known results and bounds for codes over fields. In particular, we propose a new family of locally recoverable codes by extending a construction proposed in 2014 by Tamo&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05286v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05286v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05286v1-abstract-full\" style=\"display: none;\">\\n        Locally recoverable codes deal with the task of reconstructing a lost symbol by relying on a portion of the remaining coordinates smaller than an information set. We consider the case of codes over finite chain rings, generalizing known results and bounds for codes over fields. In particular, we propose a new family of locally recoverable codes by extending a construction proposed in 2014 by Tamo and Barg, and we discuss its optimality.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05286v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05286v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05273\">arXiv:2401.05273</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05273\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05273\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Pereira%2C+J\">Jayr Pereira</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Assumpcao%2C+A\">Andre Assumpcao</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Trecenti%2C+J\">Julio Trecenti</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Airosa%2C+L\">Luiz Airosa</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Lente%2C+C\">Caio Lente</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Cl%C3%A9to%2C+J\">Jhonatan Cl\\xc3\\xa9to</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Dobins%2C+G\">Guilherme Dobins</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Nogueira%2C+R\">Rodrigo Nogueira</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Mitchell%2C+L\">Luis Mitchell</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Lotufo%2C+R\">Roberto Lotufo</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05273v1-abstract-short\" style=\"display: inline;\">\\n        This paper introduces INACIA (Instru\\xc3\\xa7\\xc3\\xa3o Assistida com Intelig\\xc3\\xaancia Artificial), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU). The system automates various stages of case analysis, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05273v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05273v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05273v1-abstract-full\" style=\"display: none;\">\\n        This paper introduces INACIA (Instru\\xc3\\xa7\\xc3\\xa3o Assistida com Intelig\\xc3\\xaancia Artificial), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU). The system automates various stages of case analysis, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation. Through a series of experiments, we demonstrate INACIA&#39;s potential in extracting relevant information from case documents, evaluating its legal plausibility, and generating judicial recommendations. Utilizing a validation dataset alongside LLMs, our evaluation methodology presents an innovative approach to assessing system performance, correlating highly with human judgment. The results highlight INACIA&#39;s proficiency in handling complex legal tasks, indicating its suitability for augmenting efficiency and judicial fairness within legal systems. The paper also discusses potential enhancements and future applications, positioning INACIA as a model for worldwide AI integration in legal domains.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05273v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05273v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05272\">arXiv:2401.05272</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05272\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05272\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Robotics\">cs.RO</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        CineMPC: A Fully Autonomous Drone Cinematography System Incorporating Zoom, Focus, Pose, and Scene Composition\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Pueyo%2C+P\">Pablo Pueyo</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Dendarieta%2C+J\">Juan Dendarieta</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Montijano%2C+E\">Eduardo Montijano</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Murillo%2C+A+C\">Ana C. Murillo</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Schwager%2C+M\">Mac Schwager</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05272v1-abstract-short\" style=\"display: inline;\">\\n        We present CineMPC, a complete cinematographic system that autonomously controls a drone to film multiple targets recording user-specified aesthetic objectives. Existing solutions in autonomous cinematography control only the camera extrinsics, namely its position, and orientation. In contrast, CineMPC is the first solution that includes the camera intrinsic parameters in the control loop, which a&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05272v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05272v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05272v1-abstract-full\" style=\"display: none;\">\\n        We present CineMPC, a complete cinematographic system that autonomously controls a drone to film multiple targets recording user-specified aesthetic objectives. Existing solutions in autonomous cinematography control only the camera extrinsics, namely its position, and orientation. In contrast, CineMPC is the first solution that includes the camera intrinsic parameters in the control loop, which are essential tools for controlling cinematographic effects like focus, depth-of-field, and zoom. The system estimates the relative poses between the targets and the camera from an RGB-D image and optimizes a trajectory for the extrinsic and intrinsic camera parameters to film the artistic and technical requirements specified by the user. The drone and the camera are controlled in a nonlinear Model Predicted Control (MPC) loop by re-optimizing the trajectory at each time step in response to current conditions in the scene. The perception system of CineMPC can track the targets&#39; position and orientation despite the camera effects. Experiments in a photorealistic simulation and with a real platform demonstrate the capabilities of the system to achieve a full array of cinematographic effects that are not possible without the control of the intrinsics of the camera. Code for CineMPC is implemented following a modular architecture in ROS and released to the community.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05272v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05272v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05268\">arXiv:2401.05268</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05268\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05268\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Human-Computer Interaction\">cs.HC</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Multiagent Systems\">cs.MA</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        AUTOACT: Automatic Agent Learning from Scratch via Self-Planning\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Qiao%2C+S\">Shuofei Qiao</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+N\">Ningyu Zhang</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Fang%2C+R\">Runnan Fang</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Luo%2C+Y\">Yujie Luo</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Zhou%2C+W\">Wangchunshu Zhou</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Jiang%2C+Y+E\">Yuchen Eleanor Jiang</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Lv%2C+C\">Chengfei Lv</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Chen%2C+H\">Huajun Chen</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05268v1-abstract-short\" style=\"display: inline;\">\\n        Language agents have achieved considerable performance on various complex tasks. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework that does not rely on large-sc&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05268v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05268v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05268v1-abstract-full\" style=\"display: none;\">\\n        Language agents have achieved considerable performance on various complex tasks. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework that does not rely on large-scale annotated data and synthetic trajectories from closed-source models (e.g., GPT-4). Given limited data with a tool library, AutoAct first automatically synthesizes planning trajectories without any assistance from humans or strong closed-source models. Then, AutoAct leverages a division-of-labor strategy to automatically differentiate based on the target task information and synthesized trajectories, producing a sub-agent group to complete the task. We conduct comprehensive experiments with different LLMs, which demonstrates that AutoAct yields better or parallel performance compared to various strong baselines. We even notice that AutoAct, when using the Llama-2-13b model, can achieve performance comparable to that of the GPT-3.5-Turbo agent. Code will be available at https://github.com/zjunlp/AutoAct.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05268v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05268v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Work in progress</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05254\">arXiv:2401.05254</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05254\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05254\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computers and Society\">cs.CY</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Language-based Valence and Arousal Expressions between the United States and China: a Cross-Cultural Examination\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Cho%2C+Y\">Young-Min Cho</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Pang%2C+D\">Dandan Pang</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Thapa%2C+S\">Stuti Thapa</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Sherman%2C+G\">Garrick Sherman</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Ungar%2C+L\">Lyle Ungar</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Tay%2C+L\">Louis Tay</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Guntuku%2C+S+C\">Sharath Chandra Guntuku</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05254v1-abstract-short\" style=\"display: inline;\">\\n        Although affective expressions of individuals have been extensively studied using social media, research has primarily focused on the Western context. There are substantial differences among cultures that contribute to their affective expressions. This paper examines the differences between Twitter (X) in the United States and Sina Weibo posts in China on two primary dimensions of affect - valence&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05254v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05254v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05254v1-abstract-full\" style=\"display: none;\">\\n        Although affective expressions of individuals have been extensively studied using social media, research has primarily focused on the Western context. There are substantial differences among cultures that contribute to their affective expressions. This paper examines the differences between Twitter (X) in the United States and Sina Weibo posts in China on two primary dimensions of affect - valence and arousal. We study the difference in the functional relationship between arousal and valence (so-called V-shaped) among individuals in the US and China and explore the associated content differences. Furthermore, we correlate word usage and topics in both platforms to interpret their differences. We observe that for Twitter users, the variation in emotional intensity is less distinct between negative and positive emotions compared to Weibo users, and there is a sharper escalation in arousal corresponding with heightened emotions. From language features, we discover that affective expressions are associated with personal life and feelings on Twitter, while on Weibo such discussions are about socio-political topics in the society. These results suggest a West-East difference in the V-shaped relationship between valence and arousal of affective expressions on social media influenced by content differences. Our findings have implications for applications and theories related to cultural differences in affective expressions.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05254v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05254v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05252\">arXiv:2401.05252</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05252\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05252\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        PIXART-\\xce\\xb4: Fast and Controllable Image Generation with Latent Consistency Models\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Chen%2C+J\">Junsong Chen</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Wu%2C+Y\">Yue Wu</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Luo%2C+S\">Simian Luo</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Xie%2C+E\">Enze Xie</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Paul%2C+S\">Sayak Paul</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Luo%2C+P\">Ping Luo</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Zhao%2C+H\">Hang Zhao</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Li%2C+Z\">Zhenguo Li</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05252v1-abstract-short\" style=\"display: inline;\">\\n        This technical report introduces PIXART-\\xce\\xb4, a text-to-image synthesis framework that integrates the Latent Consistency Model (LCM) and ControlNet into the advanced PIXART-\\xce\\xb1 model. PIXART-\\xce\\xb1 is recognized for its ability to generate high-quality images of 1024px resolution through a remarkably efficient training process. The integration of LCM in PIXART-\\xce\\xb4 significantly accelerates the inference speed&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05252v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05252v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05252v1-abstract-full\" style=\"display: none;\">\\n        This technical report introduces PIXART-\\xce\\xb4, a text-to-image synthesis framework that integrates the Latent Consistency Model (LCM) and ControlNet into the advanced PIXART-\\xce\\xb1 model. PIXART-\\xce\\xb1 is recognized for its ability to generate high-quality images of 1024px resolution through a remarkably efficient training process. The integration of LCM in PIXART-\\xce\\xb4 significantly accelerates the inference speed, enabling the production of high-quality images in just 2-4 steps. Notably, PIXART-\\xce\\xb4 achieves a breakthrough 0.5 seconds for generating 1024x1024 pixel images, marking a 7x improvement over the PIXART-\\xce\\xb1. Additionally, PIXART-\\xce\\xb4 is designed to be efficiently trainable on 32GB V100 GPUs within a single day. With its 8-bit inference capability (von Platen et al., 2023), PIXART-\\xce\\xb4 can synthesize 1024px images within 8GB GPU memory constraints, greatly enhancing its usability and accessibility. Furthermore, incorporating a ControlNet-like module enables fine-grained control over text-to-image diffusion models. We introduce a novel ControlNet-Transformer architecture, specifically tailored for Transformers, achieving explicit controllability alongside high-quality image generation. As a state-of-the-art, open-source image generation model, PIXART-\\xce\\xb4 offers a promising alternative to the Stable Diffusion family of models, contributing significantly to text-to-image synthesis.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05252v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05252v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Technical Report</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05251\">arXiv:2401.05251</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05251\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05251\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Systems and Control\">eess.SY</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        ReACT: Reinforcement Learning for Controller Parametrization using B-Spline Geometries\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Rudolf%2C+T\">Thomas Rudolf</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Fl%C3%B6gel%2C+D\">Daniel Fl\\xc3\\xb6gel</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Sch%C3%BCrmann%2C+T\">Tobias Sch\\xc3\\xbcrmann</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=S%C3%BC%C3%9F%2C+S\">Simon S\\xc3\\xbc\\xc3\\x9f</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Schwab%2C+S\">Stefan Schwab</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Hohmann%2C+S\">S\\xc3\\xb6ren Hohmann</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05251v1-abstract-short\" style=\"display: inline;\">\\n        Robust and performant controllers are essential for industrial applications. However, deriving controller parameters for complex and nonlinear systems is challenging and time-consuming. To facilitate automatic controller parametrization, this work presents a novel approach using deep reinforcement learning (DRL) with N-dimensional B-spline geometries (BSGs). We focus on the control of parameter-va&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05251v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05251v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05251v1-abstract-full\" style=\"display: none;\">\\n        Robust and performant controllers are essential for industrial applications. However, deriving controller parameters for complex and nonlinear systems is challenging and time-consuming. To facilitate automatic controller parametrization, this work presents a novel approach using deep reinforcement learning (DRL) with N-dimensional B-spline geometries (BSGs). We focus on the control of parameter-variant systems, a class of systems with complex behavior which depends on the operating conditions. For this system class, gain-scheduling control structures are widely used in applications across industries due to well-known design principles. Facilitating the expensive controller parametrization task regarding these control structures, we deploy an DRL agent. Based on control system observations, the agent autonomously decides how to adapt the controller parameters. We make the adaptation process more efficient by introducing BSGs to map the controller parameters which may depend on numerous operating conditions. To preprocess time-series data and extract a fixed-length feature vector, we use a long short-term memory (LSTM) neural networks. Furthermore, this work contributes actor regularizations that are relevant to real-world environments which differ from training. Accordingly, we apply dropout layer normalization to the actor and critic networks of the truncated quantile critic (TQC) algorithm. To show our approach&#39;s working principle and effectiveness, we train and evaluate the DRL agent on the parametrization task of an industrial control structure with parameter lookup tables.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05251v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05251v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">7 pages, 7 figures, accepted at the 2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC), Honolulu, HI, USA</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05249\">arXiv:2401.05249</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05249\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05249\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        CASA: Causality-driven Argument Sufficiency Assessment\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+X\">Xiao Liu</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Feng%2C+Y\">Yansong Feng</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Chang%2C+K\">Kai-Wei Chang</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05249v1-abstract-short\" style=\"display: inline;\">\\n        The argument sufficiency assessment task aims to determine if the premises of a given argument support its conclusion. To tackle this task, existing works often train a classifier on data annotated by humans. However, annotating data is laborious, and annotations are often inconsistent due to subjective criteria. Motivated by the probability of sufficiency (PS) definition in the causal literature,&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05249v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05249v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05249v1-abstract-full\" style=\"display: none;\">\\n        The argument sufficiency assessment task aims to determine if the premises of a given argument support its conclusion. To tackle this task, existing works often train a classifier on data annotated by humans. However, annotating data is laborious, and annotations are often inconsistent due to subjective criteria. Motivated by the probability of sufficiency (PS) definition in the causal literature, we propose CASA, a zero-shot causality-driven argument sufficiency assessment framework. PS measures how likely introducing the premise event would lead to the conclusion, when both the premise and conclusion events are absent. To estimate this probability, we propose to use large language models (LLMs) to generate contexts that are inconsistent with the premise and conclusion, and revise them by injecting the premise event. Experiments on two logical fallacy detection datasets demonstrate that CASA accurately identifies insufficient arguments. We further deploy CASA in a writing assistance application, and find that suggestions generated by CASA enhance the sufficiency of student-written arguments. Code and data are available at https://github.com/xxxiaol/CASA.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05249v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05249v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Project website: https://xxxiaol.github.io/CASA/</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05247\">arXiv:2401.05247</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05247\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05247\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Information Theory\">cs.IT</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Computing efficiently a parity-check matrix for Zps-additive codes\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Fern%C3%A1ndez-C%C3%B3rdoba%2C+C\">Cristina Fern\\xc3\\xa1ndez-C\\xc3\\xb3rdoba</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Torres%2C+A\">Adri\\xc3\\xa1n Torres</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Vela%2C+C\">Carlos Vela</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Villanueva%2C+M\">Merc\\xc3\\xa8 Villanueva</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05247v1-abstract-short\" style=\"display: inline;\">\\n        The Zps-additive codes of length n are subgroups of Zps^n , and can be seen as a generalization of linear codes over Z2, Z4, or more general over Z2s . In this paper, we show two methods for computing a parity-check matrix of a Zps-additive code from a generator matrix of the code in standard form. We also compare the performance of our results implemented in Magma with the current available funct&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05247v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05247v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05247v1-abstract-full\" style=\"display: none;\">\\n        The Zps-additive codes of length n are subgroups of Zps^n , and can be seen as a generalization of linear codes over Z2, Z4, or more general over Z2s . In this paper, we show two methods for computing a parity-check matrix of a Zps-additive code from a generator matrix of the code in standard form. We also compare the performance of our results implemented in Magma with the current available function in Magma for codes over finite rings in general. A time complexity analysis is also shown.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05247v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05247v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05244\">arXiv:2401.05244</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05244\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05244\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">stat.ML</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Applications\">stat.AP</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computation\">stat.CO</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Reliability Analysis of Complex Systems using Subset Simulations with Hamiltonian Neural Networks\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Thaler%2C+D\">Denny Thaler</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Dhulipala%2C+S+L+N\">Somayajulu L. N. Dhulipala</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Bamer%2C+F\">Franz Bamer</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Markert%2C+B\">Bernd Markert</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Shields%2C+M+D\">Michael D. Shields</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05244v1-abstract-short\" style=\"display: inline;\">\\n        We present a new Subset Simulation approach using Hamiltonian neural network-based Monte Carlo sampling for reliability analysis. The proposed strategy combines the superior sampling of the Hamiltonian Monte Carlo method with computationally efficient gradient evaluations using Hamiltonian neural networks. This combination is especially advantageous because the neural network architecture conserve&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05244v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05244v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05244v1-abstract-full\" style=\"display: none;\">\\n        We present a new Subset Simulation approach using Hamiltonian neural network-based Monte Carlo sampling for reliability analysis. The proposed strategy combines the superior sampling of the Hamiltonian Monte Carlo method with computationally efficient gradient evaluations using Hamiltonian neural networks. This combination is especially advantageous because the neural network architecture conserves the Hamiltonian, which defines the acceptance criteria of the Hamiltonian Monte Carlo sampler. Hence, this strategy achieves high acceptance rates at low computational cost. Our approach estimates small failure probabilities using Subset Simulations. However, in low-probability sample regions, the gradient evaluation is particularly challenging. The remarkable accuracy of the proposed strategy is demonstrated on different reliability problems, and its efficiency is compared to the traditional Hamiltonian Monte Carlo method. We note that this approach can reach its limitations for gradient estimations in low-probability regions of complex and high-dimensional distributions. Thus, we propose techniques to improve gradient prediction in these particular situations and enable accurate estimations of the probability of failure. The highlight of this study is the reliability analysis of a system whose parameter distributions must be inferred with Bayesian inference problems. In such a case, the Hamiltonian Monte Carlo method requires a full model evaluation for each gradient evaluation and, therefore, comes at a very high cost. However, using Hamiltonian neural networks in this framework replaces the expensive model evaluation, resulting in tremendous improvements in computational efficiency.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05244v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05244v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05240\">arXiv:2401.05240</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05240\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05240\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Decoupling Decision-Making in Fraud Prevention through Classifier Calibration for Business Logic Action\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Luzio%2C+E\">Emanuele Luzio</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Ponti%2C+M+A\">Moacir Antonelli Ponti</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Arevalo%2C+C+R\">Christian Ramirez Arevalo</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Argerich%2C+L\">Luis Argerich</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05240v1-abstract-short\" style=\"display: inline;\">\\n        Machine learning models typically focus on specific targets like creating classifiers, often based on known population feature distributions in a business context. However, models calculating individual features adapt over time to improve precision, introducing the concept of decoupling: shifting from point evaluation to data distribution. We use calibration strategies as strategy for decoupling m&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05240v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05240v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05240v1-abstract-full\" style=\"display: none;\">\\n        Machine learning models typically focus on specific targets like creating classifiers, often based on known population feature distributions in a business context. However, models calculating individual features adapt over time to improve precision, introducing the concept of decoupling: shifting from point evaluation to data distribution. We use calibration strategies as strategy for decoupling machine learning (ML) classifiers from score-based actions within business logic frameworks. To evaluate these strategies, we perform a comparative analysis using a real-world business scenario and multiple ML models. Our findings highlight the trade-offs and performance implications of the approach, offering valuable insights for practitioners seeking to optimize their decoupling efforts. In particular, the Isotonic and Beta calibration methods stand out for scenarios in which there is shift between training and testing data.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05240v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05240v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n      <p class=\"comments is-size-7\">\\n        <span class=\"has-text-black-bis has-text-weight-semibold\">Journal ref:</span>\\n        Long version of the paper of ACM-SAC 2024\\n      </p>\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05239\">arXiv:2401.05239</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05239\">pdf</a>, <a href=\"https://arxiv.org/ps/2401.05239\">ps</a>, <a href=\"https://arxiv.org/format/2401.05239\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Distributed, Parallel, and Cluster Computing\">cs.DC</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Cryptography and Security\">cs.CR</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Failures of public key infrastructure: 53 year survey\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Dumitrescu%2C+A\">Adrian-Tudor Dumitrescu</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Pouwelse%2C+J\">Johan Pouwelse</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05239v1-abstract-short\" style=\"display: inline;\">\\n        The Public Key Infrastructure existed in critical infrastructure systems since the expansion of the World Wide Web, but to this day its limitations have not been completely solved. With the rise of government-driven digital identity in Europe, it is more important than ever to understand how PKI can be an efficient frame for eID and to learn from mistakes encountered by other countries in such cri&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05239v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05239v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05239v1-abstract-full\" style=\"display: none;\">\\n        The Public Key Infrastructure existed in critical infrastructure systems since the expansion of the World Wide Web, but to this day its limitations have not been completely solved. With the rise of government-driven digital identity in Europe, it is more important than ever to understand how PKI can be an efficient frame for eID and to learn from mistakes encountered by other countries in such critical systems. This survey aims to analyze the literature on the problems and risks that PKI exhibits, establish a brief timeline of its evolution in the last decades and study how it was implemented in digital identity projects.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05239v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05239v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">9 pages, 1 table, 1 figure</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05236\">arXiv:2401.05236</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05236\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05236\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Structure from Duplicates: Neural Inverse Graphics from a Pile of Objects\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Cheng%2C+T\">Tianhang Cheng</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Ma%2C+W\">Wei-Chiu Ma</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Guan%2C+K\">Kaiyu Guan</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Torralba%2C+A\">Antonio Torralba</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+S\">Shenlong Wang</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05236v1-abstract-short\" style=\"display: inline;\">\\n        Our world is full of identical objects (\\\\emphe.g., cans of coke, cars of same model). These duplicates, when seen together, provide additional and strong cues for us to effectively reason about 3D. Inspired by this observation, we introduce Structure from Duplicates (SfD), a novel inverse graphics framework that reconstructs geometry, material, and illumination from a single image containing multi&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05236v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05236v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05236v1-abstract-full\" style=\"display: none;\">\\n        Our world is full of identical objects (\\\\emphe.g., cans of coke, cars of same model). These duplicates, when seen together, provide additional and strong cues for us to effectively reason about 3D. Inspired by this observation, we introduce Structure from Duplicates (SfD), a novel inverse graphics framework that reconstructs geometry, material, and illumination from a single image containing multiple identical objects. SfD begins by identifying multiple instances of an object within an image, and then jointly estimates the 6DoF pose for all instances.An inverse graphics pipeline is subsequently employed to jointly reason about the shape, material of the object, and the environment light, while adhering to the shared geometry and material constraint across instances. Our primary contributions involve utilizing object duplicates as a robust prior for single-image inverse graphics and proposing an in-plane rotation-robust Structure from Motion (SfM) formulation for joint 6-DoF object pose estimation. By leveraging multi-view cues from a single image, SfD generates more realistic and detailed 3D reconstructions, significantly outperforming existing single image reconstruction models and multi-view reconstruction approaches with a similar or greater number of observations.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05236v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05236v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Code: https://github.com/Tianhang-Cheng/SfD</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05235\">arXiv:2401.05235</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05235\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05235\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Social and Information Networks\">cs.SI</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Optimization and Control\">math.OC</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        A Survey on Optimization Studies of Group Centrality Metrics\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Camur%2C+M+C\">Mustafa Can Camur</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Vogiatzis%2C+C\">Chrysafis Vogiatzis</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05235v1-abstract-short\" style=\"display: inline;\">\\n        Centrality metrics have become a popular concept in network science and optimization. Over the years, centrality has been used to assign importance and identify influential elements in various settings, including transportation, infrastructure, biological, and social networks, among others. That said, most of the literature has focused on nodal versions of centrality. Recently, group counterparts&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05235v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05235v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05235v1-abstract-full\" style=\"display: none;\">\\n        Centrality metrics have become a popular concept in network science and optimization. Over the years, centrality has been used to assign importance and identify influential elements in various settings, including transportation, infrastructure, biological, and social networks, among others. That said, most of the literature has focused on nodal versions of centrality. Recently, group counterparts of centrality have started attracting scientific and practitioner interest. The identification of sets of nodes that are influential within a network is becoming increasingly more important. This is even more pronounced when these sets of nodes are required to induce a certain motif or structure. In this study, we review group centrality metrics from an operations research and optimization perspective for the first time. This is particularly interesting due to the rapid evolution and development of this area in the operations research community over the last decade. We first present a historical overview of how we have reached this point in the study of group centrality. We then discuss the different structures and motifs that appear prominently in the literature, alongside the techniques and methodologies that are popular. We finally present possible avenues and directions for future work, mainly in three areas: (i) probabilistic metrics to account for randomness along with stochastic optimization techniques; (ii) structures and relaxations that have not been yet studied; and (iii) new emerging applications that can take advantage of group centrality. Our survey offers a concise review of group centrality and its intersection with network analysis and optimization.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05235v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05235v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05233\">arXiv:2401.05233</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05233\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05233\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Information Theory\">cs.IT</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Systems and Control\">eess.SY</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Optimization and Control\">math.OC</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">stat.ML</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Taming &#34;data-hungry&#34; reinforcement learning? Stability in continuous state-action spaces\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Duan%2C+Y\">Yaqi Duan</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Wainwright%2C+M+J\">Martin J. Wainwright</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05233v1-abstract-short\" style=\"display: inline;\">\\n        We introduce a novel framework for analyzing reinforcement learning (RL) in continuous state-action spaces, and use it to prove fast rates of convergence in both off-line and on-line settings. Our analysis highlights two key stability properties, relating to how changes in value functions and/or policies affect the Bellman operator and occupation measures. We argue that these properties are satisf&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05233v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05233v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05233v1-abstract-full\" style=\"display: none;\">\\n        We introduce a novel framework for analyzing reinforcement learning (RL) in continuous state-action spaces, and use it to prove fast rates of convergence in both off-line and on-line settings. Our analysis highlights two key stability properties, relating to how changes in value functions and/or policies affect the Bellman operator and occupation measures. We argue that these properties are satisfied in many continuous state-action Markov decision processes, and demonstrate how they arise naturally when using linear function approximation methods. Our analysis offers fresh perspectives on the roles of pessimism and optimism in off-line and on-line RL, and highlights the connection between off-line RL and transfer learning.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05233v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05233v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05232\">arXiv:2401.05232</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05232\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05232\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Measuring Natural Scenes SFR of Automotive Fisheye Cameras\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Jakab%2C+D\">Daniel Jakab</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Grua%2C+E+M\">Eoin Martino Grua</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Deegan%2C+B+M\">Brian Micheal Deegan</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Scanlan%2C+A\">Anthony Scanlan</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Van+De+Ven%2C+P\">Pepijn Van De Ven</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Eising%2C+C\">Ciar\\xc3\\xa1n Eising</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05232v1-abstract-short\" style=\"display: inline;\">\\n        The Modulation Transfer Function (MTF) is an important image quality metric typically used in the automotive domain. However, despite the fact that optical quality has an impact on the performance of computer vision in vehicle automation, for many public datasets, this metric is unknown. Additionally, wide field-of-view (FOV) cameras have become increasingly popular, particularly for low-speed veh&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05232v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05232v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05232v1-abstract-full\" style=\"display: none;\">\\n        The Modulation Transfer Function (MTF) is an important image quality metric typically used in the automotive domain. However, despite the fact that optical quality has an impact on the performance of computer vision in vehicle automation, for many public datasets, this metric is unknown. Additionally, wide field-of-view (FOV) cameras have become increasingly popular, particularly for low-speed vehicle automation applications. To investigate image quality in datasets, this paper proposes an adaptation of the Natural Scenes Spatial Frequency Response (NS-SFR) algorithm to suit cameras with a wide field-of-view.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05232v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05232v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Accepted for publication in the Electronic Imagine Autonomous Vehicles and Machines (EI-AVM) Conference 2024</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05226\">arXiv:2401.05226</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05226\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05226\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Data Analysis, Statistics and Probability\">physics.data-an</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Learning effective good variables from physical data\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Barletta%2C+G\">Giulio Barletta</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Trezza%2C+G\">Giovanni Trezza</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Chiavazzo%2C+E\">Eliodoro Chiavazzo</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05226v1-abstract-short\" style=\"display: inline;\">\\n        We assume that a sufficiently large database is available, where a physical property of interest and a number of associated ruling primitive variables or observables are stored. We introduce and test two machine learning approaches to discover possible groups or combinations of primitive variables: The first approach is based on regression models whereas the second on classification models. The va&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05226v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05226v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05226v1-abstract-full\" style=\"display: none;\">\\n        We assume that a sufficiently large database is available, where a physical property of interest and a number of associated ruling primitive variables or observables are stored. We introduce and test two machine learning approaches to discover possible groups or combinations of primitive variables: The first approach is based on regression models whereas the second on classification models. The variable group (here referred to as the new effective good variable) can be considered as successfully found, when the physical property of interest is characterized by the following effective invariant behaviour: In the first method, invariance of the group implies invariance of the property up to a given accuracy; in the other method, upon partition of the physical property values into two or more classes, invariance of the group implies invariance of the class. For the sake of illustration, the two methods are successfully applied to two popular empirical correlations describing the convective heat transfer phenomenon and to the Newton&#39;s law of universal gravitation.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05226v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05226v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">24 pages (main), 8 pages (suppi), 12 figures (main), 3 figures (suppi)</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05225\">arXiv:2401.05225</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05225\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05225\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Networking and Internet Architecture\">cs.NI</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        TOVAC: Tele-operated Vehicle Admission Control and Routing\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Mart%C3%ADn-P%C3%A9rez%2C+J\">Jorge Mart\\xc3\\xadn-P\\xc3\\xa9rez</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Lentisco%2C+C+M\">Carlos M. Lentisco</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Bellido%2C+L\">Luis Bellido</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Soto%2C+I\">Ignacio Soto</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Fern%C3%A1ndez%2C+D\">David Fern\\xc3\\xa1ndez</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05225v1-abstract-short\" style=\"display: inline;\">\\n        Tele-operated Driving (ToD) is a challenging use case for mobile network operators. Video captured by the built-in vehicle cameras must be streamed meeting a latency requirement of 5 ms with a 99.999% reliability. Although 5G offers high bandwidth, ultra-low latencies and high reliability; ToD service requirements are violated due to bad channel conditions. Ignoring the channel state may lead to o&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05225v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05225v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05225v1-abstract-full\" style=\"display: none;\">\\n        Tele-operated Driving (ToD) is a challenging use case for mobile network operators. Video captured by the built-in vehicle cameras must be streamed meeting a latency requirement of 5 ms with a 99.999% reliability. Although 5G offers high bandwidth, ultra-low latencies and high reliability; ToD service requirements are violated due to bad channel conditions. Ignoring the channel state may lead to over-estimate the number of ToD vehicles that can meet the service requirements, hence comprising the vehicle security. To fill this gap, in this letter we propose TOVAC, an algorithm that guarantees ToD service requirements by taking adequate admission control and routing decisions. This is achieved by using a channel-based capacity graph that determines the maximum number of vehicles that can be tele-operated in any road section. We evaluate TOVAC considering cellular deployments from Turin and show that, unlike a state of the art solution, TOVAC guarantees the ToD service requirements.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05225v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05225v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">5 pages, 5 figures</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05224\">arXiv:2401.05224</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05224\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05224\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Do Vision and Language Encoders Represent the World Similarly?\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Maniparambil%2C+M\">Mayug Maniparambil</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Akshulakov%2C+R\">Raiymbek Akshulakov</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Djilali%2C+Y+A+D\">Yasser Abdelaziz Dahou Djilali</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Narayan%2C+S\">Sanath Narayan</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Seddik%2C+M+E+A\">Mohamed El Amine Seddik</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Mangalam%2C+K\">Karttikeya Mangalam</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=O%27Connor%2C+N+E\">Noel E. O&#39;Connor</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05224v1-abstract-short\" style=\"display: inline;\">\\n        Aligned text-image encoders such as CLIP have become the de facto model for vision-language tasks. Furthermore, modality-specific encoders achieve impressive performances in their respective domains. This raises a central question: does an alignment exist between uni-modal vision and language encoders since they fundamentally represent the same physical world? Analyzing the latent spaces structure&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05224v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05224v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05224v1-abstract-full\" style=\"display: none;\">\\n        Aligned text-image encoders such as CLIP have become the de facto model for vision-language tasks. Furthermore, modality-specific encoders achieve impressive performances in their respective domains. This raises a central question: does an alignment exist between uni-modal vision and language encoders since they fundamentally represent the same physical world? Analyzing the latent spaces structure of vision and language models on image-caption benchmarks using the Centered Kernel Alignment (CKA), we find that the representation spaces of unaligned and aligned encoders are semantically similar. In the absence of statistical similarity in aligned encoders like CLIP, we show that a possible matching of unaligned encoders exists without any training. We frame this as a seeded graph-matching problem exploiting the semantic similarity between graphs and propose two methods - a Fast Quadratic Assignment Problem optimization, and a novel localized CKA metric-based matching/retrieval. We demonstrate the effectiveness of this on several downstream tasks including cross-lingual, cross-domain caption matching and image classification.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05224v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05224v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Preprint, Under Review</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05219\">arXiv:2401.05219</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05219\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05219\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computational Engineering, Finance, and Science\">cs.CE</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Distributed Monitoring for Data Distribution Shifts in Edge-ML Fraud Detection\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Karayanni%2C+N\">Nader Karayanni</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Shahla%2C+R+J\">Robert J. Shahla</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Hsiao%2C+C\">Chieh-Lien Hsiao</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05219v1-abstract-short\" style=\"display: inline;\">\\n        The digital era has seen a marked increase in financial fraud. edge ML emerged as a promising solution for smartphone payment services fraud detection, enabling the deployment of ML models directly on edge devices. This approach enables a more personalized real-time fraud detection. However, a significant gap in current research is the lack of a robust system for monitoring data distribution shift&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05219v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05219v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05219v1-abstract-full\" style=\"display: none;\">\\n        The digital era has seen a marked increase in financial fraud. edge ML emerged as a promising solution for smartphone payment services fraud detection, enabling the deployment of ML models directly on edge devices. This approach enables a more personalized real-time fraud detection. However, a significant gap in current research is the lack of a robust system for monitoring data distribution shifts in these distributed edge ML applications. Our work bridges this gap by introducing a novel open-source framework designed for continuous monitoring of data distribution shifts on a network of edge devices. Our system includes an innovative calculation of the Kolmogorov-Smirnov (KS) test over a distributed network of edge devices, enabling efficient and accurate monitoring of users behavior shifts. We comprehensively evaluate the proposed framework employing both real-world and synthetic financial transaction datasets and demonstrate the framework&#39;s effectiveness.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05219v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05219v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05218\">arXiv:2401.05218</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05218\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05218\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Invariant Causal Prediction with Locally Linear Models\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Mey%2C+A\">Alexander Mey</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Castro%2C+R+M\">Rui Manuel Castro</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05218v1-abstract-short\" style=\"display: inline;\">\\n        We consider the task of identifying the causal parents of a target variable among a set of candidate variables from observational data. Our main assumption is that the candidate variables are observed in different environments which may, for example, correspond to different settings of a machine or different time intervals in a dynamical process. Under certain assumptions different environments ca&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05218v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05218v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05218v1-abstract-full\" style=\"display: none;\">\\n        We consider the task of identifying the causal parents of a target variable among a set of candidate variables from observational data. Our main assumption is that the candidate variables are observed in different environments which may, for example, correspond to different settings of a machine or different time intervals in a dynamical process. Under certain assumptions different environments can be regarded as interventions on the observed system. We assume a linear relationship between target and covariates, which can be different in each environment with the only restriction that the causal structure is invariant across environments. This is an extension of the ICP ($\\\\textbf{I}$nvariant $\\\\textbf{C}$ausal $\\\\textbf{P}$rediction) principle by Peters et al. [2016], who assumed a fixed linear relationship across all environments. Within our proposed setting we provide sufficient conditions for identifiability of the causal parents and introduce a practical method called LoLICaP ($\\\\textbf{Lo}$cally $\\\\textbf{L}$inear $\\\\textbf{I}$nvariant $\\\\textbf{Ca}$usal $\\\\textbf{P}$rediction), which is based on a hypothesis test for parent identification using a ratio of minimum and maximum statistics. We then show in a simplified setting that the statistical power of LoLICaP converges exponentially fast in the sample size, and finally we analyze the behavior of LoLICaP experimentally in more general settings.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05218v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05218v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05217\">arXiv:2401.05217</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05217\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05217\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Image and Video Processing\">eess.IV</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Exploring Vulnerabilities of No-Reference Image Quality Assessment Models: A Query-Based Black-Box Method\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Yang%2C+C\">Chenxi Yang</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+Y\">Yujia Liu</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Li%2C+D\">Dingquan Li</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=jiang%2C+T\">Tingting jiang</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05217v1-abstract-short\" style=\"display: inline;\">\\n        No-Reference Image Quality Assessment (NR-IQA) aims to predict image quality scores consistent with human perception without relying on pristine reference images, serving as a crucial component in various visual tasks. Ensuring the robustness of NR-IQA methods is vital for reliable comparisons of different image processing techniques and consistent user experiences in recommendations. The attack m&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05217v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05217v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05217v1-abstract-full\" style=\"display: none;\">\\n        No-Reference Image Quality Assessment (NR-IQA) aims to predict image quality scores consistent with human perception without relying on pristine reference images, serving as a crucial component in various visual tasks. Ensuring the robustness of NR-IQA methods is vital for reliable comparisons of different image processing techniques and consistent user experiences in recommendations. The attack methods for NR-IQA provide a powerful instrument to test the robustness of NR-IQA. However, current attack methods of NR-IQA heavily rely on the gradient of the NR-IQA model, leading to limitations when the gradient information is unavailable. In this paper, we present a pioneering query-based black box attack against NR-IQA methods. We propose the concept of \\\\emph{score boundary} and leverage an adaptive iterative approach with multiple score boundaries. Meanwhile, the initial attack directions are also designed to leverage the characteristics of the Human Visual System (HVS). Experiments show our attack method outperforms all compared state-of-the-art methods and is far ahead of previous black-box methods. The effective DBCNN model suffers a Spearman rank-order correlation coefficient (SROCC) decline of $0.6972$ attacked by our method, revealing the vulnerability of NR-IQA to black-box attacks. The proposed attack method also provides a potent tool for further exploration into NR-IQA robustness.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05217v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05217v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05215\">arXiv:2401.05215</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05215\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05215\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Pre-trained Large Language Models for Financial Sentiment Analysis\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Luo%2C+W\">Wei Luo</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Gong%2C+D\">Dihong Gong</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05215v1-abstract-short\" style=\"display: inline;\">\\n        Financial sentiment analysis refers to classifying financial text contents into sentiment categories (e.g. positive, negative, and neutral). In this paper, we focus on the classification of financial news title, which is a challenging task due to a lack of large amount of training samples. To overcome this difficulty, we propose to adapt the pretrained large language models (LLMs) [1, 2, 3] to sol&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05215v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05215v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05215v1-abstract-full\" style=\"display: none;\">\\n        Financial sentiment analysis refers to classifying financial text contents into sentiment categories (e.g. positive, negative, and neutral). In this paper, we focus on the classification of financial news title, which is a challenging task due to a lack of large amount of training samples. To overcome this difficulty, we propose to adapt the pretrained large language models (LLMs) [1, 2, 3] to solve this problem. The LLMs, which are trained from huge amount of text corpora,have an advantage in text understanding and can be effectively adapted to domain-specific task while requiring very few amount of training samples. In particular, we adapt the open-source Llama2-7B model (2023) with the supervised fine-tuning (SFT) technique [4]. Experimental evaluation shows that even with the 7B model (which is relatively small for LLMs), our approach significantly outperforms the previous state-of-the-art algorithms.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05215v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05215v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05211\">arXiv:2401.05211</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05211\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05211\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computational Physics\">physics.comp-ph</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Systems and Control\">eess.SY</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Dynamical Systems\">math.DS</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Error estimation for physics-informed neural networks with implicit Runge-Kutta methods\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Stiasny%2C+J\">Jochen Stiasny</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Chatzivasileiadis%2C+S\">Spyros Chatzivasileiadis</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05211v1-abstract-short\" style=\"display: inline;\">\\n        The ability to accurately approximate trajectories of dynamical systems enables their analysis, prediction, and control. Neural network (NN)-based approximations have attracted significant interest due to fast evaluation with good accuracy over long integration time steps. In contrast to established numerical approximation schemes such as Runge-Kutta methods, the estimation of the error of the NN-&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05211v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05211v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05211v1-abstract-full\" style=\"display: none;\">\\n        The ability to accurately approximate trajectories of dynamical systems enables their analysis, prediction, and control. Neural network (NN)-based approximations have attracted significant interest due to fast evaluation with good accuracy over long integration time steps. In contrast to established numerical approximation schemes such as Runge-Kutta methods, the estimation of the error of the NN-based approximations proves to be difficult. In this work, we propose to use the NN&#39;s predictions in a high-order implicit Runge-Kutta (IRK) method. The residuals in the implicit system of equations can be related to the NN&#39;s prediction error, hence, we can provide an error estimate at several points along a trajectory. We find that this error estimate highly correlates with the NN&#39;s prediction error and that increasing the order of the IRK method improves this estimate. We demonstrate this estimation methodology for Physics-Informed Neural Network (PINNs) on the logistic equation as an illustrative example and then apply it to a four-state electric generator model that is regularly used in power system modelling.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05211v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05211v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Submitted to the 6th Annual Conference on Learning for Dynamics and Control, 2024</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05206\">arXiv:2401.05206</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05206\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05206\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computational Physics\">physics.comp-ph</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Tailoring Frictional Properties of Surfaces Using Diffusion Models\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Nordhagen%2C+E+M\">Even Marius Nordhagen</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Sveinsson%2C+H+A\">Henrik Andersen Sveinsson</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Malthe-S%C3%B8renssen%2C+A\">Anders Malthe-S\\xc3\\xb8renssen</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05206v1-abstract-short\" style=\"display: inline;\">\\n        This Letter introduces an approach for precisely designing surface friction properties using a conditional generative machine learning model, specifically a diffusion denoising probabilistic model (DDPM). We created a dataset of synthetic surfaces with frictional properties determined by molecular dynamics simulations, which trained the DDPM to predict surface structures from desired frictional ou&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05206v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05206v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05206v1-abstract-full\" style=\"display: none;\">\\n        This Letter introduces an approach for precisely designing surface friction properties using a conditional generative machine learning model, specifically a diffusion denoising probabilistic model (DDPM). We created a dataset of synthetic surfaces with frictional properties determined by molecular dynamics simulations, which trained the DDPM to predict surface structures from desired frictional outcomes. Unlike traditional trial-and-error and numerical optimization methods, our approach directly yields surface designs meeting specified frictional criteria with high accuracy and efficiency. This advancement in material surface engineering demonstrates the potential of machine learning in reducing the iterative nature of surface design processes. Our findings not only provide a new pathway for precise surface property tailoring but also suggest broader applications in material science where surface characteristics are critical.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05206v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05206v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 5 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05204\">arXiv:2401.05204</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05204\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05204\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts into a Verbalizer\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Ma%2C+Y\">Yong Ma</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Luo%2C+S\">Senlin Luo</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Shang%2C+Y\">Yu-Ming Shang</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Li%2C+Z\">Zhengjun Li</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Liu%2C+Y\">Yong Liu</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05204v1-abstract-short\" style=\"display: inline;\">\\n        The verbalizer, which serves to map label words to class labels, is an essential component of prompt-tuning. In this paper, we present a novel approach to constructing verbalizers. While existing methods for verbalizer construction mainly rely on augmenting and refining sets of synonyms or related words based on class names, this paradigm suffers from a narrow perspective and lack of abstraction,&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05204v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05204v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05204v1-abstract-full\" style=\"display: none;\">\\n        The verbalizer, which serves to map label words to class labels, is an essential component of prompt-tuning. In this paper, we present a novel approach to constructing verbalizers. While existing methods for verbalizer construction mainly rely on augmenting and refining sets of synonyms or related words based on class names, this paradigm suffers from a narrow perspective and lack of abstraction, resulting in limited coverage and high bias in the label-word space. To address this issue, we propose a label-word construction process that incorporates scenario-specific concepts. Specifically, we extract rich concepts from task-specific scenarios as label-word candidates and then develop a novel cascade calibration module to refine the candidates into a set of label words for each class. We evaluate the effectiveness of our proposed approach through extensive experiments on {five} widely used datasets for zero-shot text classification. The results demonstrate that our method outperforms existing methods and achieves state-of-the-art results.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05204v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05204v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05202\">arXiv:2401.05202</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05202\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05202\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computer Vision and Pattern Recognition\">cs.CV</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Video-based Automatic Lameness Detection of Dairy Cows using Pose Estimation and Multiple Locomotion Traits\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Russello%2C+H\">Helena Russello</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=van+der+Tol%2C+R\">Rik van der Tol</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Holzhauer%2C+M\">Menno Holzhauer</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=van+Henten%2C+E+J\">Eldert J. van Henten</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Kootstra%2C+G\">Gert Kootstra</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05202v1-abstract-short\" style=\"display: inline;\">\\n        This study presents an automated lameness detection system that uses deep-learning image processing techniques to extract multiple locomotion traits associated with lameness. Using the T-LEAP pose estimation model, the motion of nine keypoints was extracted from videos of walking cows. The videos were recorded outdoors, with varying illumination conditions, and T-LEAP extracted 99.6% of correct ke&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05202v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05202v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05202v1-abstract-full\" style=\"display: none;\">\\n        This study presents an automated lameness detection system that uses deep-learning image processing techniques to extract multiple locomotion traits associated with lameness. Using the T-LEAP pose estimation model, the motion of nine keypoints was extracted from videos of walking cows. The videos were recorded outdoors, with varying illumination conditions, and T-LEAP extracted 99.6% of correct keypoints. The trajectories of the keypoints were then used to compute six locomotion traits: back posture measurement, head bobbing, tracking distance, stride length, stance duration, and swing duration. The three most important traits were back posture measurement, head bobbing, and tracking distance. For the ground truth, we showed that a thoughtful merging of the scores of the observers could improve intra-observer reliability and agreement. We showed that including multiple locomotion traits improves the classification accuracy from 76.6% with only one trait to 79.9% with the three most important traits and to 80.1% with all six locomotion traits.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05202v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05202v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05200\">arXiv:2401.05200</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05200\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05200\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Human-Computer Interaction\">cs.HC</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Information Retrieval\">cs.IR</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Knowledge Sharing in Manufacturing using Large Language Models: User Evaluation and Model Benchmarking\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Freire%2C+S+K\">Samuel Kernan Freire</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Wang%2C+C\">Chaofan Wang</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Foosherian%2C+M\">Mina Foosherian</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Wellsandt%2C+S\">Stefan Wellsandt</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Ruiz-Arenas%2C+S\">Santiago Ruiz-Arenas</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Niforatos%2C+E\">Evangelos Niforatos</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05200v1-abstract-short\" style=\"display: inline;\">\\n        Managing knowledge efficiently is crucial for organizational success. In manufacturing, operating factories has become increasing knowledge-intensive putting strain on the factory&#39;s capacity to train and support new operators. In this paper, we introduce a Large Language Model (LLM)-based system designed to use the extensive knowledge contained in factory documentation. The system aims to efficien&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05200v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05200v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05200v1-abstract-full\" style=\"display: none;\">\\n        Managing knowledge efficiently is crucial for organizational success. In manufacturing, operating factories has become increasing knowledge-intensive putting strain on the factory&#39;s capacity to train and support new operators. In this paper, we introduce a Large Language Model (LLM)-based system designed to use the extensive knowledge contained in factory documentation. The system aims to efficiently answer queries from operators and facilitate the sharing of new knowledge. To assess its effectiveness, we conducted an evaluation in a factory setting. The results of this evaluation demonstrated the system&#39;s benefits; namely, in enabling quicker information retrieval and more efficient resolution of issues. However, the study also highlighted a preference for learning from a human expert when such an option is available. Furthermore, we benchmarked several closed and open-sourced LLMs for this system. GPT-4 consistently outperformed its counterparts, with open-source models like StableBeluga2 trailing closely, presenting an attractive option given its data privacy and customization benefits. Overall, this work offers preliminary insights for factories considering using LLM-tools for knowledge management.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05200v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05200v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">13 pages, 3 figures, and 1 table. Under review</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05199\">arXiv:2401.05199</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05199\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05199\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Computation and Language\">cs.CL</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Monte Carlo Tree Search for Recipe Generation using GPT-2\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Taneja%2C+K\">Karan Taneja</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Segal%2C+R\">Richard Segal</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Goodwin%2C+R\">Richard Goodwin</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05199v1-abstract-short\" style=\"display: inline;\">\\n        Automatic food recipe generation methods provide a creative tool for chefs to explore and to create new, and interesting culinary delights. Given the recent success of large language models (LLMs), they have the potential to create new recipes that can meet individual preferences, dietary constraints, and adapt to what is in your refrigerator. Existing research on using LLMs to generate recipes ha&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05199v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05199v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05199v1-abstract-full\" style=\"display: none;\">\\n        Automatic food recipe generation methods provide a creative tool for chefs to explore and to create new, and interesting culinary delights. Given the recent success of large language models (LLMs), they have the potential to create new recipes that can meet individual preferences, dietary constraints, and adapt to what is in your refrigerator. Existing research on using LLMs to generate recipes has shown that LLMs can be finetuned to generate realistic-sounding recipes. However, on close examination, these generated recipes often fail to meet basic requirements like including chicken as an ingredient in chicken dishes. In this paper, we propose RecipeMC, a text generation method using GPT-2 that relies on Monte Carlo Tree Search (MCTS). RecipeMC allows us to define reward functions to put soft constraints on text generation and thus improve the credibility of the generated recipes. Our results show that human evaluators prefer recipes generated with RecipeMC more often than recipes generated with other baseline methods when compared with real recipes.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05199v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05199v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">10 pages, 1 figure, ICCC 2023</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05196\">arXiv:2401.05196</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05196\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05196\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Optimization and Control\">math.OC</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Information Theory\">cs.IT</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Accelerated Bregmann divergence optimization with SMART: an information geometry point of view\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Raus%2C+M\">Maren Raus</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Elshiaty%2C+Y\">Yara Elshiaty</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Petra%2C+S\">Stefania Petra</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05196v1-abstract-short\" style=\"display: inline;\">\\n        We investigate the problem of minimizing Kullback-Leibler divergence between a linear model $Ax$ and a positive vector $b$ in different convex domains (positive orthant, $n$-dimensional box, probability simplex). Our focus is on the SMART method that employs efficient multiplicative updates. We explore the exponentiated gradient method, which can be viewed as a Bregman proximal gradient method and&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05196v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05196v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05196v1-abstract-full\" style=\"display: none;\">\\n        We investigate the problem of minimizing Kullback-Leibler divergence between a linear model $Ax$ and a positive vector $b$ in different convex domains (positive orthant, $n$-dimensional box, probability simplex). Our focus is on the SMART method that employs efficient multiplicative updates. We explore the exponentiated gradient method, which can be viewed as a Bregman proximal gradient method and as a Riemannian gradient descent on the parameter manifold of a corresponding distribution of the exponential family. This dual interpretation enables us to establish connections and achieve accelerated SMART iterates while smoothly incorporating constraints. The performance of the proposed acceleration schemes is demonstrated by large-scale numerical examples.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05196v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05196v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">37 pages, 11 figures, 3 tables, 4 algorithms. Submitted to Journal of Applied and Numerical Optimization for the Special Issue Dedicated to Prof. Yair Censor</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05194\">arXiv:2401.05194</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05194\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05194\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Robotics\">cs.RO</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Systems and Control\">eess.SY</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Modelling, Positioning, and Deep Reinforcement Learning Path Tracking Control of Scaled Robotic Vehicles: Design and Experimental Validation\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Caponio%2C+C\">Carmine Caponio</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Stano%2C+P\">Pietro Stano</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Carli%2C+R\">Raffaele Carli</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Olivieri%2C+I\">Ignazio Olivieri</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Ragone%2C+D\">Daniele Ragone</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Sorniotti%2C+A\">Aldo Sorniotti</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Montanaro%2C+U\">Umberto Montanaro</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05194v1-abstract-short\" style=\"display: inline;\">\\n        Mobile robotic systems are becoming increasingly popular. These systems are used in various indoor applications, raging from warehousing and manufacturing to test benches for assessment of advanced control strategies, such as artificial intelligence (AI)-based control solutions, just to name a few. Scaled robotic cars are commonly equipped with a hierarchical control acthiecture that includes task&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05194v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05194v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05194v1-abstract-full\" style=\"display: none;\">\\n        Mobile robotic systems are becoming increasingly popular. These systems are used in various indoor applications, raging from warehousing and manufacturing to test benches for assessment of advanced control strategies, such as artificial intelligence (AI)-based control solutions, just to name a few. Scaled robotic cars are commonly equipped with a hierarchical control acthiecture that includes tasks dedicated to vehicle state estimation and control. This paper covers both aspects by proposing (i) a federeted extended Kalman filter (FEKF), and (ii) a novel deep reinforcement learning (DRL) path tracking controller trained via an expert demonstrator to expedite the learning phase and increase robustess to the simulation-to-reality gap. The paper also presents the formulation of a vehicle model along with an effective yet simple procedure for identifying tis paramters. The experimentally validated model is used for (i) supporting the design of the FEKF and (ii) serving as a digital twin for training the proposed DRL-based path tracking algorithm. Experimental results confirm the ability of the FEKF to improve the estimate of the mobile robot&#39;s position. Furthermore, the effectiveness of the DRL path tracking strateguy is experimentally tested along manoeuvres not considered during training, showing also the ability of the AI-based solution to outpeform model-based control strategies and the demonstrator. The comparison with benchmraking controllers is quantitavely evalueted through a set of key performance indicators.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05194v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05194v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Under review on IEEE Transactions</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05193\">arXiv:2401.05193</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05193\">pdf</a>, <a href=\"https://arxiv.org/ps/2401.05193\">ps</a>, <a href=\"https://arxiv.org/format/2401.05193\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">cs.LG</span>\\n        \\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Artificial Intelligence\">cs.AI</span>\\n          \\n            <span class=\"tag is-small is-grey tooltip is-tooltip-top\" data-tooltip=\"Machine Learning\">stat.ML</span>\\n          \\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Experiment Planning with Function Approximation\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Pacchiano%2C+A\">Aldo Pacchiano</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Lee%2C+J+N\">Jonathan N. Lee</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Brunskill%2C+E\">Emma Brunskill</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05193v1-abstract-short\" style=\"display: inline;\">\\n        We study the problem of experiment planning with function approximation in contextual bandit problems. In settings where there is a significant overhead to deploying adaptive algorithms -- for example, when the execution of the data collection policies is required to be distributed, or a human in the loop is needed to implement these policies -- producing in advance a set of policies for data coll&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05193v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05193v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05193v1-abstract-full\" style=\"display: none;\">\\n        We study the problem of experiment planning with function approximation in contextual bandit problems. In settings where there is a significant overhead to deploying adaptive algorithms -- for example, when the execution of the data collection policies is required to be distributed, or a human in the loop is needed to implement these policies -- producing in advance a set of policies for data collection is paramount. We study the setting where a large dataset of contexts but not rewards is available and may be used by the learner to design an effective data collection strategy. Although when rewards are linear this problem has been well studied, results are still missing for more complex reward models. In this work we propose two experiment planning strategies compatible with function approximation. The first is an eluder planning and sampling procedure that can recover optimality guarantees depending on the eluder dimension of the reward function class. For the second, we show that a uniform sampler achieves competitive optimality rates in the setting where the number of actions is small. We finalize our results introducing a statistical gap fleshing out the fundamental differences between planning and adaptive learning and provide results for planning with model selection.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05193v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05193v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">10 pages main</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n  <li class=\"arxiv-result\">\\n    <div class=\"is-marginless\">\\n      <p class=\"list-title is-inline-block\"><a href=\"https://arxiv.org/abs/2401.05191\">arXiv:2401.05191</a>\\n        <span>&nbsp;[<a href=\"https://arxiv.org/pdf/2401.05191\">pdf</a>, <a href=\"https://arxiv.org/format/2401.05191\">other</a>]&nbsp;</span>\\n      </p>\\n      <div class=\"tags is-inline-block\">\\n        <span class=\"tag is-small is-link tooltip is-tooltip-top\" data-tooltip=\"Information Retrieval\">cs.IR</span>\\n        </div>\\n      \\n    </div>\\n    \\n    <p class=\"title is-5 mathjax\">\\n      \\n        Adaptive Hardness Negative Sampling for Collaborative Filtering\\n      \\n    </p>\\n    <p class=\"authors\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Authors:</span>\\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Lai%2C+R\">Riwei Lai</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Chen%2C+R\">Rui Chen</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Han%2C+Q\">Qilong Han</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Zhang%2C+C\">Chi Zhang</a>, \\n      \\n      <a href=\"/search/?searchtype=author&amp;query=Chen%2C+L\">Li Chen</a>\\n      \\n    </p>\\n    \\n    <p class=\"abstract mathjax\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Abstract</span>:\\n      <span class=\"abstract-short has-text-grey-dark mathjax\" id=\"2401.05191v1-abstract-short\" style=\"display: inline;\">\\n        Negative sampling is essential for implicit collaborative filtering to provide proper negative training signals so as to achieve desirable performance. We experimentally unveil a common limitation of all existing negative sampling methods that they can only select negative samples of a fixed hardness level, leading to the false positive problem (FPP) and false negative problem (FNP). We then propo&hellip;\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05191v1-abstract-full\\').style.display = \\'inline\\'; document.getElementById(\\'2401.05191v1-abstract-short\\').style.display = \\'none\\';\">&#9661; More</a>\\n      </span>\\n      <span class=\"abstract-full has-text-grey-dark mathjax\" id=\"2401.05191v1-abstract-full\" style=\"display: none;\">\\n        Negative sampling is essential for implicit collaborative filtering to provide proper negative training signals so as to achieve desirable performance. We experimentally unveil a common limitation of all existing negative sampling methods that they can only select negative samples of a fixed hardness level, leading to the false positive problem (FPP) and false negative problem (FNP). We then propose a new paradigm called adaptive hardness negative sampling (AHNS) and discuss its three key criteria. By adaptively selecting negative samples with appropriate hardnesses during the training process, AHNS can well mitigate the impacts of FPP and FNP. Next, we present a concrete instantiation of AHNS called AHNS_{p&lt;0}, and theoretically demonstrate that AHNS_{p&lt;0} can fit the three criteria of AHNS well and achieve a larger lower bound of normalized discounted cumulative gain. Besides, we note that existing negative sampling methods can be regarded as more relaxed cases of AHNS. Finally, we conduct comprehensive experiments, and the results show that AHNS_{p&lt;0} can consistently and substantially outperform several state-of-the-art competitors on multiple datasets.\\n        <a class=\"is-size-7\" style=\"white-space: nowrap;\" onclick=\"document.getElementById(\\'2401.05191v1-abstract-full\\').style.display = \\'none\\'; document.getElementById(\\'2401.05191v1-abstract-short\\').style.display = \\'inline\\';\">&#9651; Less</a>\\n      </span>\\n    </p>\\n    \\n\\n    <p class=\"is-size-7\"><span class=\"has-text-black-bis has-text-weight-semibold\">Submitted</span> 10 January, 2024; \\n      <span class=\"has-text-black-bis has-text-weight-semibold\">originally announced</span> January 2024.\\n      \\n    </p>\\n    \\n    <p class=\"comments is-size-7\">\\n      <span class=\"has-text-black-bis has-text-weight-semibold\">Comments:</span>\\n      <span class=\"has-text-grey-dark mathjax\">Accepted by AAAI2024</span>\\n    </p>\\n    \\n\\n    \\n\\n    \\n  </li>\\n\\n</ol>\\n\\n\\n  <nav class=\"pagination is-small is-centered breathe-horizontal\" role=\"navigation\" aria-label=\"pagination\">\\n    \\n    <a href=\"\"\\n      class=\"pagination-previous is-invisible\">Previous\\n    </a>\\n    \\n    \\n      <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=50\"\\n        class=\"pagination-next\" >Next\\n      </a>\\n    \\n    <ul class=\"pagination-list\">\\n\\n      <li>\\n        <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=0\"\\n          class=\"pagination-link is-current\"\\n          aria-label=\"Goto page 1\">1\\n        </a>\\n      </li>\\n\\n      \\n                                     \\n          \\n          <li>\\n            <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=50\"\\n              class=\"pagination-link \"\\n              aria-label=\"Page 2\"\\n              aria-current=\"page\">2\\n            </a>\\n          </li>\\n          \\n          <li>\\n            <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=100\"\\n              class=\"pagination-link \"\\n              aria-label=\"Page 3\"\\n              aria-current=\"page\">3\\n            </a>\\n          </li>\\n          \\n          <li>\\n            <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=150\"\\n              class=\"pagination-link \"\\n              aria-label=\"Page 4\"\\n              aria-current=\"page\">4\\n            </a>\\n          </li>\\n          \\n          <li>\\n            <a href=\"/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=&amp;terms-0-field=title&amp;classification-computer_science=y&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first&amp;start=200\"\\n              class=\"pagination-link \"\\n              aria-label=\"Page 5\"\\n              aria-current=\"page\">5\\n            </a>\\n          </li>\\n          \\n          <li><span class=\"pagination-ellipsis\">&hellip;</span></li>\\n        \\n      \\n    </ul>\\n  </nav>\\n  \\n\\n    \\n  \\n\\n      <div class=\"is-hidden-tablet\">\\n        <!-- feedback for mobile only -->\\n        <span class=\"help\" style=\"display: inline-block;\"><a href=\"https://github.com/arXiv/arxiv-search/releases\">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>\\n      </div>\\n    </div>\\n\\n  </main>\\n  <footer>\\n    \\n    <div class=\"columns is-desktop\" role=\"navigation\" aria-label=\"Secondary\">\\n  <!-- MetaColumn 1 -->\\n  <div class=\"column\">\\n    <div class=\"columns\">\\n      <div class=\"column\">\\n        <ul class=\"nav-spaced\">\\n          <li><a href=\"https://arxiv.org/about\">About</a></li>\\n          <li><a href=\"https://arxiv.org/help\">Help</a></li>\\n        </ul>\\n      </div>\\n      <div class=\"column\">\\n        <ul class=\"nav-spaced\">\\n          <li>\\n            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"/></svg>\\n            <a href=\"https://arxiv.org/help/contact\"> Contact</a>\\n          </li>\\n          <li>\\n            <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d=\"M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z\"/></svg>\\n            <a href=\"https://arxiv.org/help/subscribe\"> Subscribe</a>\\n          </li>\\n        </ul>\\n      </div>\\n    </div>\\n  </div> <!-- end MetaColumn 1 -->\\n  <!-- MetaColumn 2 -->\\n  <div class=\"column\">\\n    <div class=\"columns\">\\n      <div class=\"column\">\\n        <ul class=\"nav-spaced\">\\n          <li><a href=\"https://arxiv.org/help/license\">Copyright</a></li>\\n          <li><a href=\"https://arxiv.org/help/policies/privacy_policy\">Privacy Policy</a></li>\\n        </ul>\\n      </div>\\n      <div class=\"column sorry-app-links\">\\n        <ul class=\"nav-spaced\">\\n          <li><a href=\"https://arxiv.org/help/web_accessibility\">Web Accessibility Assistance</a></li>\\n          <li>\\n            <p class=\"help\">\\n              <a class=\"a11y-main-link\" href=\"https://status.arxiv.org\" target=\"_blank\">arXiv Operational Status <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\" class=\"icon filter-dark_grey\" role=\"presentation\"><path d=\"M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z\"/></svg></a><br>\\n              Get status notifications via\\n              <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/email/new\" target=\"_blank\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"/></svg>email</a>\\n              or <a class=\"is-link\" href=\"https://subscribe.sorryapp.com/24846f03/slack/new\" target=\"_blank\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\" class=\"icon filter-black\" role=\"presentation\"><path d=\"M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z\"/></svg>slack</a>\\n            </p>\\n          </li>\\n        </ul>\\n      </div>\\n    </div>\\n  </div> <!-- end MetaColumn 2 -->\\n</div>\\n    \\n  </footer>\\n  </body>\\n</html>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=&terms-0-field=title&classification-computer_science=y&classification-physics_archives=all&classification-include_cross_list=include&date-filter_by=all_dates&date-year=&date-from_date=&date-to_date=&date-date_type=submitted_date&abstracts=show&size=50&order=-announced_date_first&start=0'\n",
    "response = requests.get(url)\n",
    "response = response.content\n",
    "pattern = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = soup.find_all('li', class_='arxiv-result')\n",
    "df = pd.DataFrame()\n",
    "for i in range(len(papers)):\n",
    "    title = papers[i].find('p',class_='title')\n",
    "    authors = papers[i].find_all('p',class_='authors')\n",
    "    noob_authors = []\n",
    "    for author in authors:\n",
    "        author_names = author.find_all('a')\n",
    "        for author_name in author_names:\n",
    "            noob_authors.append(author_name.text)\n",
    "    abstracts = papers[i].find('span',class_='abstract-full')\n",
    "    \n",
    "    pdf_link = papers[i].find('span')\n",
    "    pdf_link = pdf_link.find('a')\n",
    "    noob_data = {'title':'','authors':'','abstract':'','pdf_link':''}\n",
    "    noob_data['title'] = title.text.strip()\n",
    "    noob_data['authors'] = noob_authors\n",
    "    noob_data['abstract'] = abstracts.text\n",
    "    noob_data['pdf_link'] = pdf_link['href']\n",
    "    df = df.from_dict(noob_data)\n",
    "    df.to_csv('wow.csv')\n",
    "\n",
    "    # data[i+1] = noob_data\n",
    "# df = pd.DataFrame()\n",
    "# for i in range(len(data)):\n",
    "#     df = df.from_dict(data[i+1])\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
